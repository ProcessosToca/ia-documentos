import os
import re
import json
from openai import OpenAI
from typing import Dict, Any, List
import logging
from datetime import datetime

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIService:
    """Servi√ßo para integra√ß√£o com OpenAI"""
    
    def __init__(self):
        # Configurar cliente OpenAI
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
    def interpretar_mensagem(self, mensagem: str) -> Dict[str, Any]:
        """
        Interpreta a mensagem do usu√°rio usando OpenAI
        
        Args:
            mensagem (str): Mensagem do usu√°rio
            
        Returns:
            Dict: Resultado da interpreta√ß√£o com campos:
                - cpf: CPF encontrado ou None
                - novo_usuario: True se for sauda√ß√£o/primeiro contato, False caso contr√°rio
                - solicitar_cpf: True se precisa solicitar CPF
                - mensagem_resposta: Mensagem para enviar ao usu√°rio
        """
        try:
            # Prompt para a OpenAI
            prompt = f"""Como uma Corretora de Loca√ß√£o, analise a mensagem do cliente:

            Mensagem: {mensagem}

            1. Identifique se √© uma sauda√ß√£o ou primeiro contato
            2. Procure por um CPF na mensagem
            3. Determine a pr√≥xima a√ß√£o apropriada

            Retorne apenas um objeto JSON com:
            - cpf: n√∫mero do CPF se encontrado (apenas n√∫meros), ou null se n√£o encontrado
            - novo_usuario: true se for sauda√ß√£o/primeiro contato, false caso contr√°rio
            - solicitar_cpf: true se n√£o encontrou CPF ou false se encontrou
            - mensagem_resposta: mensagem apropriada para o cliente:
              - Se for novo usu√°rio: enviar primeira mensagem padr√£o
              - Se encontrou CPF: apenas confirmar "Ol√°! Confirmo o recebimento do CPF [CPF formatado]."
              - Se n√£o encontrou CPF: solicitar gentilmente
            """
            
            # Fazer chamada para OpenAI com nova sintaxe
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": """Voc√™ √© uma Corretora de Loca√ß√£o profissional e eficiente.
                        Seu objetivo √© identificar informa√ß√µes importantes para o processo de loca√ß√£o.
                        Mantenha um tom profissional e direto.
                        Para novos usu√°rios, apresente-se como Bia e solicite o CPF.
                        Para confirma√ß√£o de CPF, apenas confirme o recebimento sem perguntas adicionais.
                        """
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            # Extrair resposta
            resultado = json.loads(response.choices[0].message.content)
            logger.info("ü§ñ Interpreta√ß√£o conclu√≠da")
            
            return resultado
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao interpretar mensagem: {str(e)}")
            return {
                "cpf": None,
                "novo_usuario": False,
                "solicitar_cpf": True,
                "mensagem_resposta": "Por favor, me envie seu CPF (apenas n√∫meros) para continuarmos o atendimento."
            } 

    def analisar_conversas_com_gpt(self, conversas: List[dict], documentos_analise: dict) -> dict:
        """
        Analisa o hist√≥rico de conversas e documentos de uma negocia√ß√£o usando GPT-4 para gerar uma resposta contextual.
        
        Args:
            conversas (List[dict]): Lista de conversas anteriores, cada uma com:
                - sender: 'ia' ou 'user'
                - message: texto da mensagem
                - timestamp: quando foi enviada
            documentos_analise (dict): An√°lise dos documentos da negocia√ß√£o com:
                - total_obrigatorios: n√∫mero total de documentos necess√°rios
                - total_recebidos: n√∫mero de documentos j√° recebidos
                - total_faltantes: n√∫mero de documentos pendentes
                - documentos_faltantes: lista de documentos que faltam
                - progresso_percentual: % de conclus√£o
                
        Returns:
            dict: Resultado da an√°lise com:
                - resumo: Resumo do contexto atual da conversa
                - proxima_mensagem: Texto sugerido para pr√≥xima mensagem
                - contexto: Situa√ß√£o atual (ex: "aguardando_documentos", "documentos_completos")
                
        Exemplo:
            >>> conversas = [
                    {"sender": "user", "message": "Bom dia, enviei o RG"},
                    {"sender": "ia", "message": "Recebi! Falta comprovante de renda"}
                ]
            >>> docs = {
                    "total_obrigatorios": 3,
                    "total_recebidos": 1,
                    "documentos_faltantes": [{"name": "Comprovante de Renda"}]
                }
            >>> resultado = analisar_conversas_com_gpt(conversas, docs)
            >>> print(resultado["proxima_mensagem"])
            "Por favor, envie seu comprovante de renda para continuarmos."
        """
        try:
            # Preparar hist√≥rico de conversas para an√°lise
            historico = []
            for conversa in conversas:
                papel = "assistant" if conversa['sender'] == 'ia' else "user"
                historico.append(f"{papel.upper()}: {conversa['message']}")
            
            # Valida√ß√£o e acesso seguro aos dados de documentos
            total_obrigatorios = documentos_analise.get('total_obrigatorios', 0)
            total_recebidos = documentos_analise.get('total_recebidos', 0)
            total_faltantes = documentos_analise.get('total_faltantes', 0)
            progresso_percentual = documentos_analise.get('progresso_percentual', 0.0)
            documentos_faltantes = documentos_analise.get('documentos_faltantes', [])
            documentos_recebidos = documentos_analise.get('documentos_recebidos', [])
            
            logger.info(f"üìä Analisando: {total_recebidos}/{total_obrigatorios} documentos ({progresso_percentual:.1f}%)")
            
            # Preparar lista de documentos faltantes de forma segura
            docs_faltantes_lista = []
            for doc in documentos_faltantes:
                nome = doc.get('name', 'Documento n√£o identificado')
                descricao = doc.get('description', 'Sem descri√ß√£o')
                docs_faltantes_lista.append(f"üìÑ *{nome}* - {descricao}")
            
            # Preparar lista de documentos recebidos
            docs_recebidos_lista = []
            for doc in documentos_recebidos:
                nome_tipo = doc.get('ai_document_types', {}).get('name', 'Documento')
                docs_recebidos_lista.append(f"‚úÖ {nome_tipo}")
            
            # Preparar informa√ß√µes sobre documentos
            docs_info = f"""
            DOCUMENTOS OBRIGAT√ìRIOS: {total_obrigatorios}
            DOCUMENTOS RECEBIDOS: {total_recebidos}
            DOCUMENTOS FALTANTES: {total_faltantes}
            PROGRESSO: {progresso_percentual:.1f}%
            
            DOCUMENTOS J√Å RECEBIDOS:
            {chr(10).join(docs_recebidos_lista) if docs_recebidos_lista else "Nenhum documento recebido ainda"}
            
            DOCUMENTOS FALTANTES:
            {chr(10).join(docs_faltantes_lista) if docs_faltantes_lista else "Nenhum documento faltante"}
            """
            
            # Determinar contexto atual baseado nos dados
            if total_obrigatorios == 0:
                contexto_atual = "sem_documentos_definidos"
            elif total_faltantes == 0 and total_recebidos > 0:
                contexto_atual = "documentos_completos"
            elif total_recebidos > 0:
                contexto_atual = "aguardando_documentos"
            else:
                contexto_atual = "iniciando_coleta"
            
            # Prompt para GPT-4
            prompt = f"""
            Voc√™ √© um assistente IA especializado em negocia√ß√µes imobili√°rias. Analise o hist√≥rico de conversas abaixo e as informa√ß√µes sobre documentos para:

            1. RESUMIR onde parou a conversa
            2. IDENTIFICAR o que o cliente precisa fazer agora
            3. SUGERIR a pr√≥xima mensagem apropriada

            HIST√ìRICO DE CONVERSAS ({len(historico)} mensagens):
            {chr(10).join(historico) if historico else "Nenhuma conversa anterior"}

            SITUA√á√ÉO DOS DOCUMENTOS:
            {docs_info}

            CONTEXTO ATUAL: {contexto_atual}

            INSTRU√á√ïES:
            - Seja cordial e profissional
            - Se faltam documentos, mencione ESPECIFICAMENTE quais documentos est√£o faltando com suas descri√ß√µes
                        - Use formata√ß√£o com quebras de linha para melhor legibilidade no WhatsApp:
              "Recebi seu RG ‚úÖ
              
              Ainda preciso de:
              üìÑ *Comprovante de Renda* - √∫ltimos 3 holerites
              üè† *Comprovante de Resid√™ncia* - conta de luz/√°gua  
              üìã *Certid√£o de Nascimento/Casamento* - estado civil
              
              Me pe√ßa para enviar documentos que inicio a sequ√™ncia de envios com voc√™! üìÑ"
            - Se todos os documentos foram enviados, informe o pr√≥ximo passo
            - Mantenha o tom conversacional e amig√°vel
            - Use emojis para deixar mais amig√°vel
            - Use quebras de linha para separar as informa√ß√µes
            - Se n√£o h√° conversas anteriores, seja acolhedor e explique o processo

            Responda em JSON com:
            - "resumo": Resumo do contexto atual
            - "proxima_mensagem": Mensagem para enviar ao cliente
            - "contexto": Situa√ß√£o atual (ex: "aguardando_documentos", "documentos_completos", "iniciando_conversa")
            """
            
            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente especializado em an√°lise de conversas imobili√°rias. Responda sempre em JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # Processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            
            # Tentar fazer parse do JSON
            try:
                resultado = json.loads(resposta_texto)
                logger.info(f"‚úÖ An√°lise GPT-4 conclu√≠da com sucesso")
                return resultado
            except json.JSONDecodeError:
                logger.warning(f"‚ö†Ô∏è Resposta GPT-4 n√£o √© JSON v√°lido: {resposta_texto[:200]}...")
                
                # Tentar extrair mensagem √∫til do texto mal formado
                mensagem_limpa = resposta_texto
                
                # Se cont√©m estrutura JSON parcial, tentar extrair a mensagem
                if '"proxima_mensagem"' in resposta_texto:
                    try:
                        # Buscar o conte√∫do da proxima_mensagem
                        match = re.search(r'"proxima_mensagem":\s*"([^"]*)"', resposta_texto)
                        if match:
                            mensagem_limpa = match.group(1)
                            logger.info(f"‚úÖ Mensagem extra√≠da do JSON parcial")
                        else:
                            # Fallback: usar texto ap√≥s dois pontos
                            if ':"' in resposta_texto:
                                mensagem_limpa = resposta_texto.split(':"')[1].split('"')[0]
                    except Exception as e_regex:
                        logger.warning(f"‚ö†Ô∏è Erro ao extrair mensagem: {e_regex}")
                        # Usar mensagem padr√£o se falhar
                        mensagem_limpa = "Analisei sua situa√ß√£o e vou continuar te ajudando com os pr√≥ximos passos!"
                else:
                    # Se n√£o tem estrutura JSON, usar o texto direto mas limitar tamanho
                    mensagem_limpa = resposta_texto[:200] if len(resposta_texto) > 200 else resposta_texto
                    # Remover caracteres JSON comuns que possam aparecer
                    mensagem_limpa = mensagem_limpa.replace('{"', '').replace('"}', '').replace('\\n', '\n')
                
                return {
                    "resumo": "An√°lise conclu√≠da com texto n√£o estruturado",
                    "proxima_mensagem": mensagem_limpa,
                    "contexto": "analise_texto_livre"
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise GPT-4: {str(e)}")
            return {
                "resumo": f"Erro na an√°lise: {str(e)}",
                "proxima_mensagem": "Vou analisar sua situa√ß√£o e retorno em breve. Obrigado pela paci√™ncia!",
                "contexto": "erro_analise"
            }

    def interpretar_intencao_mensagem(self, mensagem: str, remetente: str = None) -> Dict[str, Any]:
        """
        Interpretador inteligente para detectar inten√ß√µes em mensagens usando GPT
        
        Esta fun√ß√£o √© o INTERPRETADOR CENTRAL que processa TODAS as mensagens
        antes do fluxo principal, identificando:
        - Sauda√ß√µes (oi, ol√°, bom dia) ‚Üí Primeira mensagem da Bia
        - Solicita√ß√µes de menu (menu, op√ß√µes) ‚Üí Menu apropriado por tipo de usu√°rio
        - Conversas normais ‚Üí Continua fluxo original
        
        Args:
            mensagem (str): Texto da mensagem recebida do usu√°rio
            remetente (str, optional): N√∫mero do telefone (para contexto futuro)
            
        Returns:
            Dict com an√°lise da inten√ß√£o:
                - intencao: "saudacao" | "menu" | "conversa_normal" | "duvida_tecnica"
                - confianca: 0.0-1.0 (n√≠vel de certeza da IA)
                - bypass_fluxo: True se deve interceptar, False se continua normal
                - contexto: "primeira_interacao" | "usuario_conhecido"
                - acao_sugerida: "primeira_mensagem" | "enviar_menu" | "continuar_fluxo"
        
        Exemplo de uso:
            >>> interpretacao = service.interpretar_intencao_mensagem("oi, tudo bem?")
            >>> print(interpretacao["intencao"])  # "saudacao"
            >>> print(interpretacao["bypass_fluxo"])  # True
        """
        try:
            logger.info(f"üß† Interpretando inten√ß√£o da mensagem: {mensagem[:50]}...")
            
            # Prompt especializado para detectar inten√ß√µes
            prompt = f"""Analise esta mensagem do WhatsApp e identifique a inten√ß√£o do usu√°rio:

MENSAGEM: "{mensagem}"

Classifique a inten√ß√£o como:

1. "saudacao" - Se cont√©m cumprimentos como: oi, ol√°, bom dia, boa tarde, boa noite, hey, e a√≠, tudo bem, como vai, etc.

2. "menu" - Se solicita navega√ß√£o como: menu, op√ß√µes, voltar menu, menu inicial, mostrar op√ß√µes, escolhas, navegar, etc.

3. "conversa_normal" - Se cont√©m: CPF, n√∫meros, perguntas espec√≠ficas, documentos, informa√ß√µes pessoais

4. "duvida_tecnica" - Se cont√©m perguntas sobre: loca√ß√£o, processos, contratos, documenta√ß√£o, an√°lise, negocia√ß√£o

IMPORTANTE:
- Alta confian√ßa (>0.8) apenas se for CLARAMENTE uma sauda√ß√£o ou solicita√ß√£o de menu
- M√©dia confian√ßa (0.5-0.8) se houver d√∫vida
- Baixa confian√ßa (<0.5) se for amb√≠guo

Responda APENAS em JSON v√°lido:
{{
  "intencao": "saudacao|menu|conversa_normal|duvida_tecnica",
  "confianca": 0.0,
  "bypass_fluxo": true/false,
  "contexto": "primeira_interacao|usuario_conhecido",
  "acao_sugerida": "primeira_mensagem|enviar_menu|continuar_fluxo"
}}"""

            # Chamada para GPT com configura√ß√µes otimizadas
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """Voc√™ √© um analisador especializado em inten√ß√µes de mensagens para um sistema de atendimento imobili√°rio.

Sua fun√ß√£o √© identificar com precis√£o a inten√ß√£o real do usu√°rio:

- SAUDA√á√ïES: Cumprimentos gerais e iniciais de conversa
- MENU: Solicita√ß√µes expl√≠citas de navega√ß√£o ou op√ß√µes
- CONVERSA_NORMAL: Informa√ß√µes espec√≠ficas como CPF, dados pessoais
- DUVIDA_TECNICA: Perguntas sobre processos, contratos, loca√ß√£o

Seja conservador: apenas classifique como "saudacao" ou "menu" se tiver ALTA CERTEZA.
Caso contr√°rio, use "conversa_normal" para manter o fluxo original funcionando.

SEMPRE retorne JSON v√°lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consist√™ncia
                max_tokens=150    # Resposta curta e objetiva
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Resposta GPT: {resposta_texto[:100]}...")
            
            try:
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar campos obrigat√≥rios
                campos_obrigatorios = ["intencao", "confianca", "bypass_fluxo", "acao_sugerida"]
                for campo in campos_obrigatorios:
                    if campo not in resultado:
                        raise ValueError(f"Campo obrigat√≥rio ausente: {campo}")
                
                # Ajustar bypass_fluxo baseado na inten√ß√£o e confian√ßa
                if resultado["confianca"] < 0.7:
                    resultado["bypass_fluxo"] = False
                    resultado["acao_sugerida"] = "continuar_fluxo"
                else:
                    # Para sauda√ß√µes e menu com alta confian√ßa, sempre fazer bypass
                    if resultado["intencao"] in ["saudacao", "menu"]:
                        resultado["bypass_fluxo"] = True
                        if resultado["intencao"] == "saudacao":
                            resultado["acao_sugerida"] = "primeira_mensagem"
                        elif resultado["intencao"] == "menu":
                            resultado["acao_sugerida"] = "enviar_menu"
                
                logger.info(f"‚úÖ Inten√ß√£o detectada: {resultado['intencao']} (confian√ßa: {resultado['confianca']})")
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON do GPT: {e}")
                # Fallback: continuar fluxo normal
                return {
                    "intencao": "conversa_normal",
                    "confianca": 0.0,
                    "bypass_fluxo": False,
                    "contexto": "usuario_conhecido", 
                    "acao_sugerida": "continuar_fluxo",
                    "erro": "json_parse_error"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no interpretador de inten√ß√µes: {str(e)}")
            # Fallback seguro: sempre continuar fluxo normal em caso de erro
            return {
                "intencao": "conversa_normal",
                "confianca": 0.0,
                "bypass_fluxo": False,
                "contexto": "usuario_conhecido",
                "acao_sugerida": "continuar_fluxo",
                "erro": str(e)
            }


    def validar_dado_cliente(self, tipo_dado: str, valor: str) -> Dict[str, Any]:
        """
        Valida dados do cliente coletados durante processo de fechamento usando GPT
        
        Esta fun√ß√£o usa IA para validar se os dados fornecidos pelo colaborador
        s√£o v√°lidos para um processo de loca√ß√£o imobili√°ria.
        
        Args:
            tipo_dado (str): Tipo do dado a validar ("nome" | "telefone")
            valor (str): Valor fornecido pelo colaborador para valida√ß√£o
            
        Returns:
            Dict com resultado da valida√ß√£o:
                - valido: True se dado √© v√°lido, False se inv√°lido
                - valor_corrigido: Valor formatado/corrigido se necess√°rio
                - motivo_erro: Explica√ß√£o se inv√°lido
                - sugestao: Sugest√£o de corre√ß√£o se aplic√°vel
        
        Exemplos de uso:
            >>> resultado = service.validar_dado_cliente("nome", "Jo√£o Silva")
            >>> print(resultado["valido"])  # True
            
            >>> resultado = service.validar_dado_cliente("telefone", "11999999999")
            >>> print(resultado["valor_corrigido"])  # "(11) 99999-9999"
        """
        try:
            logger.info(f"üîç Validando {tipo_dado}: {valor[:30]}...")
            
            if tipo_dado == "nome":
                # Prompt para valida√ß√£o de nome
                prompt = f"""Analise se este √© um nome v√°lido para um cliente de loca√ß√£o imobili√°ria:

NOME: "{valor}"

Crit√©rios FLEX√çVEIS de valida√ß√£o:
1. Deve conter pelo menos 2 palavras (nome + sobrenome)
2. Deve usar caracteres alfab√©ticos (permitir acentos, espa√ßos)
3. N√£o deve conter n√∫meros ou s√≠mbolos especiais
4. Deve parecer um nome real de pessoa
5. Aceitar nomes compostos, duplos, estrangeiros

Exemplos V√ÅLIDOS: "Jo√£o Silva", "Maria Santos", "Jos√© da Silva", "Ana Beatriz", "Carlos Eduardo", "Andreia Robe", "Maria Jos√©", "Jo√£o Pedro"
Exemplos INV√ÅLIDOS: "Jo√£o", "123", "abc", "Jo√£o123", "@#$", "X Y", "A B"

IMPORTANTE: Seja FLEX√çVEL com nomes reais. Se parece um nome de pessoa v√°lido com pelo menos 2 palavras, ACEITE.

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Nome formatado corretamente",
  "motivo_erro": "Explica√ß√£o se inv√°lido",
  "sugestao": "Sugest√£o de corre√ß√£o se necess√°rio"
}}"""

            elif tipo_dado == "telefone":
                # Prompt para valida√ß√£o de telefone
                prompt = f"""Analise se este √© um telefone v√°lido brasileiro:

TELEFONE: "{valor}"

Crit√©rios de valida√ß√£o:
1. Deve ter 10 ou 11 d√≠gitos (com DDD)
2. DDD v√°lido brasileiro (11-99)
3. N√∫mero de celular ou fixo v√°lido
4. Pode ter ou n√£o formata√ß√£o
5. N√£o deve conter letras

Exemplos V√ÅLIDOS: "11999999999", "(11) 99999-9999", "1133334444"
Exemplos INV√ÅLIDOS: "999999999", "abc", "123", "00999999999"

Se v√°lido, formate como: (XX) XXXXX-XXXX para celular ou (XX) XXXX-XXXX para fixo

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Telefone formatado: (XX) XXXXX-XXXX",
  "motivo_erro": "Explica√ß√£o se inv√°lido",
  "sugestao": "Sugest√£o de corre√ß√£o se necess√°rio"
}}"""

            else:
                return {
                    "valido": False,
                    "motivo_erro": f"Tipo de dado n√£o suportado: {tipo_dado}",
                    "sugestao": "Use 'nome' ou 'telefone'"
                }

            # Chamada para GPT com configura√ß√µes de valida√ß√£o
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """Voc√™ √© um validador especializado em dados de clientes para processos imobili√°rios.

Sua fun√ß√£o √© verificar se os dados fornecidos s√£o v√°lidos e √∫teis para um processo de loca√ß√£o.

Seja rigoroso na valida√ß√£o:
- Nomes devem ser completos e reais
- Telefones devem ser brasileiros v√°lidos
- Sempre formate corretamente os dados v√°lidos
- Forne√ßa explica√ß√µes claras para dados inv√°lidos

SEMPRE retorne JSON v√°lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consist√™ncia na valida√ß√£o
                max_tokens=200
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Valida√ß√£o GPT: {resposta_texto[:100]}...")
            
            try:
                # Parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar campos obrigat√≥rios
                if "valido" not in resultado:
                    raise ValueError("Campo 'valido' ausente na resposta")
                
                # Adicionar informa√ß√µes de contexto
                resultado.update({
                    "tipo_dado": tipo_dado,
                    "valor_original": valor,
                    "timestamp_validacao": "now"
                })
                
                status = "‚úÖ V√ÅLIDO" if resultado["valido"] else "‚ùå INV√ÅLIDO"
                logger.info(f"{status} - {tipo_dado}: {valor[:20]}...")
                
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON de valida√ß√£o: {e}")
                # Fallback: considerar inv√°lido se n√£o conseguir processar
                return {
                    "valido": False,
                    "motivo_erro": "Erro interno na valida√ß√£o",
                    "sugestao": f"Tente novamente com um {tipo_dado} mais claro",
                    "erro_processamento": str(e)
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico na valida√ß√£o de dados: {str(e)}")
            # Fallback seguro: sempre rejeitar em caso de erro
            return {
                "valido": False,
                "motivo_erro": "Erro t√©cnico na valida√ß√£o",
                "sugestao": f"Tente novamente fornecendo o {tipo_dado}",
                "erro_critico": str(e)
            }

    def responder_duvida_locacao(self, duvida: str, contexto_colaborador: dict = None) -> Dict[str, Any]:
        """
        IA especializada em responder d√∫vidas sobre negocia√ß√£o de loca√ß√£o para colaboradores
        
        Esta fun√ß√£o √© chamada quando um colaborador seleciona "Usar IA para D√∫vidas" no menu
        e envia uma pergunta relacionada a processos de loca√ß√£o, documentos, negocia√ß√£o, etc.
        
        Args:
            duvida (str): Pergunta/d√∫vida do colaborador sobre loca√ß√£o
            contexto_colaborador (dict, optional): Dados do colaborador (setor, nome, etc.)
            
        Returns:
            Dict: Resposta estruturada com:
                - resposta: Texto da resposta especializada
                - categoria: Categoria da d√∫vida (documentos, processo, juridico, etc.)
                - confianca: N√≠vel de confian√ßa da resposta (alto/medio/baixo)
                - sugestoes_extras: Sugest√µes adicionais se aplic√°vel
                
        Exemplo:
            >>> resultado = responder_duvida_locacao("Como validar comprovante de renda?")
            >>> print(resultado["resposta"])
            "Para validar comprovante de renda, voc√™ deve verificar..."
        """
        try:
            logger.info(f"ü§ñ Processando d√∫vida de loca√ß√£o: {duvida[:50]}...")
            
            # Extrair informa√ß√µes do colaborador se dispon√≠vel
            nome_colaborador = "Colaborador"
            setor_colaborador = "N√£o informado"
            
            if contexto_colaborador:
                nome_colaborador = contexto_colaborador.get('nome', 'Colaborador')
                setor_colaborador = contexto_colaborador.get('setor', 'N√£o informado')
            
            # Prompt especializado em negocia√ß√£o de loca√ß√£o
            prompt_sistema = """
            Voc√™ √© um ESPECIALISTA em NEGOCIA√á√ÉO DE LOCA√á√ÉO IMOBILI√ÅRIA e assistente para colaboradores da Toca Im√≥veis.

            ESPECIALIDADES:
            üè† Processos de loca√ß√£o sem fiador
            üìÑ Documenta√ß√£o necess√°ria (RG, CPF, comprovantes)
            üí∞ An√°lise de renda e capacidade financeira
            üìã Contratos e termos legais
            üîç Valida√ß√£o de documentos
            üë• Relacionamento com clientes
            ‚öñÔ∏è Aspectos jur√≠dicos b√°sicos
            üìä Fluxos e procedimentos internos

            INSTRU√á√ïES:
            - Responda de forma PR√ÅTICA e OBJETIVA
            - Use linguagem PROFISSIONAL mas ACESS√çVEL
            - Forne√ßa PASSOS CONCRETOS quando aplic√°vel
            - Mencione DOCUMENTOS ESPEC√çFICOS quando necess√°rio
            - Use EMOJIS para organizar a informa√ß√£o
            - Se n√£o souber algo espec√≠fico da Toca Im√≥veis, seja transparente
            - Foque em SOLU√á√ïES PR√ÅTICAS para o dia a dia

            FORMATO DA RESPOSTA:
            - Use quebras de linha para facilitar leitura no WhatsApp
            - Organize em t√≥picos quando necess√°rio
            - Seja direto e evite textos muito longos
            """

            prompt_usuario = f"""
            CONTEXTO DO COLABORADOR:
            üë§ Nome: {nome_colaborador}
            üè¢ Setor: {setor_colaborador}

            D√öVIDA:
            {duvida}

            Responda esta d√∫vida de forma especializada, considerando que √© um colaborador da Toca Im√≥veis que precisa de orienta√ß√£o pr√°tica para seu trabalho di√°rio.

            Formate sua resposta em JSON com:
            - "resposta": Resposta detalhada e pr√°tica para a d√∫vida
            - "categoria": Categoria da d√∫vida (documentos|processo|juridico|relacionamento|financeiro|outros)
            - "confianca": N√≠vel de confian√ßa da resposta (alto|medio|baixo)
            - "sugestoes_extras": Array com sugest√µes adicionais ou pr√≥ximos passos (m√°ximo 3 sugest√µes)
            """

            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": prompt_sistema},
                    {"role": "user", "content": prompt_usuario}
                ],
                temperature=0.3,  # Baixa temperatura para respostas mais consistentes
                max_tokens=800,   # Espa√ßo suficiente para resposta detalhada
                top_p=0.9
            )

            # Extrair e processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            
            try:
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar estrutura da resposta
                if not all(key in resultado for key in ['resposta', 'categoria', 'confianca']):
                    raise ValueError("JSON n√£o cont√©m todas as chaves necess√°rias")
                
                # Garantir que sugestoes_extras seja uma lista
                if 'sugestoes_extras' not in resultado:
                    resultado['sugestoes_extras'] = []
                elif not isinstance(resultado['sugestoes_extras'], list):
                    resultado['sugestoes_extras'] = [str(resultado['sugestoes_extras'])]
                
                logger.info(f"‚úÖ D√∫vida processada - Categoria: {resultado['categoria']}")
                logger.info(f"üéØ Confian√ßa: {resultado['confianca']}")
                
                return {
                    "sucesso": True,
                    "resposta": resultado['resposta'],
                    "categoria": resultado['categoria'],
                    "confianca": resultado['confianca'],
                    "sugestoes_extras": resultado['sugestoes_extras'],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador
                }
                
            except (json.JSONDecodeError, ValueError) as e:
                # Se JSON inv√°lido, usar resposta como texto simples
                logger.warning(f"‚ö†Ô∏è Resposta n√£o √© JSON v√°lido: {str(e)}")
                
                # Limpar a resposta e usar como texto
                resposta_limpa = resposta_texto.replace('```json', '').replace('```', '').strip()
                
                # Tentar extrair pelo menos a resposta principal
                if '"resposta"' in resposta_limpa:
                    match = re.search(r'"resposta":\s*"([^"]*)"', resposta_limpa)
                    if match:
                        resposta_limpa = match.group(1).replace('\\n', '\n')
                
                return {
                    "sucesso": True,
                    "resposta": resposta_limpa,
                    "categoria": "geral",
                    "confianca": "medio",
                    "sugestoes_extras": ["Posso esclarecer mais detalhes se precisar"],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador,
                    "aviso": "Resposta processada como texto livre"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar d√∫vida de loca√ß√£o: {str(e)}")
            
            return {
                "sucesso": False,
                "resposta": "Desculpe, tive um problema t√©cnico ao processar sua d√∫vida. Pode reformular sua pergunta ou tentar novamente em alguns instantes?",
                "categoria": "erro",
                "confianca": "baixo",
                "sugestoes_extras": [
                    "Tente reformular a pergunta",
                    "Seja mais espec√≠fico sobre o tema",
                    "Verifique se √© uma d√∫vida sobre loca√ß√£o"
                ],
                "colaborador": nome_colaborador,
                "setor": setor_colaborador,
                "erro": str(e)
            } 

    def analisar_e_limpar_conversa_json(self, conversa_json: Dict[str, Any]) -> Dict[str, Any]:
        """
        üß† NOVA FUN√á√ÉO: Usa OpenAI para analisar e limpar JSON de conversa
        
        Funcionalidades:
        - Remove mensagens duplicadas
        - Remove logs t√©cnicos e do sistema
        - Formata mensagens de menu naturalmente
        - Remove detalhes t√©cnicos como "(row_id: iniciar_fechamento)"
        - Prepara JSON otimizado para banco de dados
        
        Args:
            conversa_json (Dict): JSON da conversa original
            
        Returns:
            Dict: JSON limpo e otimizado
        """
        try:
            logger.info("üß† Iniciando an√°lise e limpeza do JSON da conversa com OpenAI...")
            
            # Extrair mensagens para an√°lise
            mensagens_originais = conversa_json.get('messages', [])
            
            if not mensagens_originais:
                logger.warning("‚ö†Ô∏è Nenhuma mensagem encontrada para analisar")
                return conversa_json
            
            # Preparar dados para OpenAI
            mensagens_para_analise = []
            for i, msg in enumerate(mensagens_originais):
                mensagens_para_analise.append({
                    "index": i,
                    "id": msg.get('id'),
                    "timestamp": msg.get('timestamp'),
                    "sender": msg.get('sender'),
                    "content": msg.get('content', '')[:500],  # Limitar tamanho
                    "message_type": msg.get('message_type'),
                    "phase": msg.get('phase')
                })
            
            # Extrair dados dos participantes para detec√ß√£o inteligente
            participants = conversa_json.get('participants', {})
            client_data = participants.get('client', {})
            client_cpf = client_data.get('cpf', '')
            client_email = client_data.get('email', '')
            
            # Prompt para OpenAI com detec√ß√£o inteligente
            prompt_analise = f"""
Analise esta conversa de WhatsApp e identifique:

1. **MENSAGENS DUPLICADAS**: Mensagens id√™nticas ou muito similares
2. **LOGS T√âCNICOS**: Mensagens que s√£o logs do sistema (ex: "üìÑ CPF PROCESSADO", detalhes t√©cnicos)
3. **MENSAGENS DO SISTEMA**: sender="system" que n√£o agregam valor
4. **FORMATA√á√ÉO DE MENUS**: Mensagens com "(row_id: ...)" devem ser naturalizadas
5. **MENSAGENS PERDIDAS**: Detectar se faltam respostas do cliente baseado no fluxo

**MENSAGENS DA CONVERSA:**
{json.dumps(mensagens_para_analise, ensure_ascii=False, indent=2)}

**DADOS DO CLIENTE (para detec√ß√£o inteligente):**
- CPF: {client_cpf}
- Email: {client_email}

**DETEC√á√ÉO INTELIGENTE (REGRA CR√çTICA):**

EXEMPLO DE PROBLEMA:
1. msg_003: IA diz "preciso do seu CPF"
2. msg_004: IA detalha "Para prosseguir, preciso do seu CPF: (n√∫meros)"
3. msg_005: IA diz "Digite seu e-mail"  ‚Üê PROBLEMA! Cliente n√£o respondeu CPF!

REGRA: Se IA pede CPF e pr√≥xima mensagem √© IA pedindo EMAIL (sem resposta do cliente), ent√£o INSERIR:
{{
  "inserir_apos_index": [√≠ndice da mensagem que pede CPF],
  "sender": "cliente", 
  "content": "{client_cpf}",
  "motivo": "Resposta de CPF perdida detectada"
}}

OUTROS PADR√ïES:
- IA pede CPF ‚Üí IA pede EMAIL = FALTA resposta CPF
- IA pede EMAIL ‚Üí IA pede DATA = FALTA resposta EMAIL
- IA pede DATA ‚Üí IA pede CEP = FALTA resposta DATA

**RESPONDA EM JSON:**
{{
  "mensagens_para_manter": [√≠ndices das mensagens que devem ser mantidas],
  "mensagens_para_remover": [√≠ndices das mensagens que devem ser removidas],
  "mensagens_para_reformatar": [
    {{
      "index": √≠ndice,
      "novo_conteudo": "nova vers√£o sem detalhes t√©cnicos"
    }}
  ],
  "mensagens_para_inserir": [
    {{
      "inserir_apos_index": √≠ndice,
      "sender": "cliente",
      "content": "resposta do cliente",
      "motivo": "mensagem perdida detectada"
    }}
  ],
  "justificativa": "explica√ß√£o breve das mudan√ßas"
}}

**REGRAS:**
- Manter TODAS as mensagens essenciais do cliente e IA
- Remover apenas duplicatas √≥bvias e logs t√©cnicos
- Naturalizar menus: "Iniciar Fechamento Loca√ß√£o" (sem row_id)
- INSERIR mensagens perdidas do cliente automaticamente
- Preservar fluxo da conversa
- Ser conservador - na d√∫vida, manter
"""

            # Chamar OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system", 
                        "content": """Voc√™ √© um especialista em an√°lise de conversas de WhatsApp. 

SUA MISS√ÉO ESPEC√çFICA: Detectar quando mensagens do cliente est√£o perdidas.

PADR√ÉO CR√çTICO A DETECTAR:
- IA pede CPF: "preciso do seu CPF"
- IA pede email: "Digite seu e-mail" (SEM o cliente ter respondido CPF)
- = PROBLEMA! Falta mensagem do cliente com CPF

QUANDO DETECTAR ESSE PADR√ÉO, voc√™ DEVE inserir a mensagem perdida usando os dados dos participants.

Seja PRECISO na detec√ß√£o de fluxos quebrados."""
                    },
                    {
                        "role": "user", 
                        "content": prompt_analise
                    }
                ],
                temperature=0.1,  # Baixa temperatura para consist√™ncia
                max_tokens=2000
            )
            
            # Processar resposta
            resposta_openai = response.choices[0].message.content.strip()
            
            # Limpar resposta removendo markdown
            resposta_limpa = resposta_openai.replace('```json', '').replace('```', '').strip()
            
            try:
                # Tentar parsear JSON da resposta
                analise = json.loads(resposta_limpa)
                logger.info(f"‚úÖ An√°lise OpenAI conclu√≠da: {analise.get('justificativa', 'N/A')}")
                
            except json.JSONDecodeError:
                logger.error("‚ùå Erro ao parsear resposta JSON da OpenAI")
                logger.error(f"Resposta recebida: {resposta_limpa}")
                return conversa_json
            
            # Aplicar as mudan√ßas recomendadas
            mensagens_limpas = self._aplicar_limpeza_conversa(
                mensagens_originais, 
                analise,
                conversa_json
            )
            
            # Criar JSON limpo
            conversa_limpa = conversa_json.copy()
            conversa_limpa['messages'] = mensagens_limpas
            
            # Atualizar estat√≠sticas
            if 'conversation_summary' in conversa_limpa:
                conversa_limpa['conversation_summary']['total_messages'] = len(mensagens_limpas)
                conversa_limpa['conversation_summary']['cleaned_by_ai'] = True
                conversa_limpa['conversation_summary']['original_count'] = len(mensagens_originais)
                conversa_limpa['conversation_summary']['removed_count'] = len(mensagens_originais) - len(mensagens_limpas)
            
            # Adicionar metadata da limpeza
            conversa_limpa['ai_cleaning'] = {
                "cleaned_at": datetime.now().isoformat(),
                "original_message_count": len(mensagens_originais),
                "cleaned_message_count": len(mensagens_limpas),
                "justificativa": analise.get('justificativa', 'Limpeza autom√°tica'),
                "removed_indices": analise.get('mensagens_para_remover', []),
                "reformatted_count": len(analise.get('mensagens_para_reformatar', [])),
                "inserted_count": len(analise.get('mensagens_para_inserir', [])),
                "inserted_messages": analise.get('mensagens_para_inserir', [])
            }
            
            logger.info(f"üßπ Limpeza conclu√≠da: {len(mensagens_originais)} ‚Üí {len(mensagens_limpas)} mensagens")
            
            return conversa_limpa
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise/limpeza da conversa: {str(e)}")
            # Em caso de erro, retornar conversa original
            return conversa_json
    
    def _aplicar_limpeza_conversa(self, mensagens_originais: List[Dict], analise: Dict, conversa_json: Dict = None) -> List[Dict]:
        """
        Aplica as recomenda√ß√µes de limpeza da OpenAI
        
        Args:
            mensagens_originais: Lista de mensagens originais
            analise: Resultado da an√°lise OpenAI
            conversa_json: JSON completo da conversa (para dados dos participants)
            
        Returns:
            List: Mensagens limpas
        """
        try:
            mensagens_limpas = []
            indices_para_remover = set(analise.get('mensagens_para_remover', []))
            reformatacoes = {item['index']: item['novo_conteudo'] 
                           for item in analise.get('mensagens_para_reformatar', [])}
            
            # Processar mensagens para inserir
            mensagens_para_inserir = {}
            for item in analise.get('mensagens_para_inserir', []):
                inserir_apos = item.get('inserir_apos_index', -1)
                mensagens_para_inserir[inserir_apos] = item
            
            for i, mensagem in enumerate(mensagens_originais):
                # Pular mensagens marcadas para remo√ß√£o
                if i in indices_para_remover:
                    logger.info(f"üóëÔ∏è Removendo mensagem {i}: {mensagem.get('content', '')[:50]}...")
                    continue
                
                # Aplicar reformata√ß√£o se necess√°rio
                if i in reformatacoes:
                    mensagem_reformatada = mensagem.copy()
                    mensagem_reformatada['content'] = reformatacoes[i]
                    mensagem_reformatada['ai_reformatted'] = True
                    mensagens_limpas.append(mensagem_reformatada)
                    logger.info(f"‚úèÔ∏è Reformatada mensagem {i}: {reformatacoes[i][:50]}...")
                else:
                    # Manter mensagem original
                    mensagens_limpas.append(mensagem)
                
                # Verificar se precisa inserir mensagem ap√≥s esta
                if i in mensagens_para_inserir:
                    nova_mensagem = mensagens_para_inserir[i]
                    
                    # Criar nova mensagem do cliente
                    mensagem_inserida = {
                        "id": f"msg_ai_inserted_{i+1}",
                        "timestamp": mensagem.get('timestamp', ''),
                        "sender": nova_mensagem.get('sender', 'cliente'),
                        "content": nova_mensagem.get('content', ''),
                        "message_type": "text",
                        "metadata": {
                            "receiver_explicit": "ia",
                            "enhanced_method": True,
                            "ai_inserted": True
                        },
                        "sender_specific": "cliente",
                        "receiver_specific": "ia",
                        "interaction_type": "cliente_ia",
                        "phase": mensagem.get('phase', 'ia_cliente'),
                        "ai_inserted": True,
                        "ai_inserted_reason": nova_mensagem.get('motivo', 'Mensagem perdida detectada')
                    }
                    
                    mensagens_limpas.append(mensagem_inserida)
                    logger.info(f"üîÑ Inserida mensagem perdida ap√≥s {i}: {nova_mensagem.get('content', '')[:50]}...")
            
            return mensagens_limpas
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao aplicar limpeza: {e}")
            return mensagens_originais 