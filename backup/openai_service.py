import os
import re
import json
from openai import OpenAI
from typing import Dict, Any, List
import logging
from datetime import datetime

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIService:
    """ServiÃ§o para integraÃ§Ã£o com OpenAI"""
    
    def __init__(self):
        # Configurar cliente OpenAI
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
    def interpretar_mensagem(self, mensagem: str) -> Dict[str, Any]:
        """
        Interpreta a mensagem do usuÃ¡rio usando OpenAI
        
        Args:
            mensagem (str): Mensagem do usuÃ¡rio
            
        Returns:
            Dict: Resultado da interpretaÃ§Ã£o com campos:
                - cpf: CPF encontrado ou None
                - novo_usuario: True se for saudaÃ§Ã£o/primeiro contato, False caso contrÃ¡rio
                - solicitar_cpf: True se precisa solicitar CPF
                - mensagem_resposta: Mensagem para enviar ao usuÃ¡rio
        """
        try:
            # Prompt para a OpenAI
            prompt = f"""Como uma Corretora de LocaÃ§Ã£o, analise a mensagem do cliente:

            Mensagem: {mensagem}

            1. Identifique se Ã© uma saudaÃ§Ã£o ou primeiro contato
            2. Procure por um CPF na mensagem
            3. Determine a prÃ³xima aÃ§Ã£o apropriada

            Retorne apenas um objeto JSON com:
            - cpf: nÃºmero do CPF se encontrado (apenas nÃºmeros), ou null se nÃ£o encontrado
            - novo_usuario: true se for saudaÃ§Ã£o/primeiro contato, false caso contrÃ¡rio
            - solicitar_cpf: true se nÃ£o encontrou CPF ou false se encontrou
            - mensagem_resposta: mensagem apropriada para o cliente:
              - Se for novo usuÃ¡rio: enviar primeira mensagem padrÃ£o
              - Se encontrou CPF: apenas confirmar "OlÃ¡! Confirmo o recebimento do CPF [CPF formatado]."
              - Se nÃ£o encontrou CPF: solicitar gentilmente
            """
            
            # Fazer chamada para OpenAI com nova sintaxe
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": """VocÃª Ã© uma Corretora de LocaÃ§Ã£o profissional e eficiente.
                        Seu objetivo Ã© identificar informaÃ§Ãµes importantes para o processo de locaÃ§Ã£o.
                        Mantenha um tom profissional e direto.
                        Para novos usuÃ¡rios, apresente-se como Bia e solicite o CPF.
                        Para confirmaÃ§Ã£o de CPF, apenas confirme o recebimento sem perguntas adicionais.
                        """
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            # Extrair resposta
            resultado = json.loads(response.choices[0].message.content)
            logger.info("ğŸ¤– InterpretaÃ§Ã£o concluÃ­da")
            
            return resultado
            
        except Exception as e:
            logger.error(f"âŒ Erro ao interpretar mensagem: {str(e)}")
            return {
                "cpf": None,
                "novo_usuario": False,
                "solicitar_cpf": True,
                "mensagem_resposta": "Por favor, me envie seu CPF (apenas nÃºmeros) para continuarmos o atendimento."
            } 

    def analisar_conversas_com_gpt(self, conversas: List[dict], documentos_analise: dict) -> dict:
        """
        Analisa o histÃ³rico de conversas e documentos de uma negociaÃ§Ã£o usando GPT-4 para gerar uma resposta contextual.
        
        Args:
            conversas (List[dict]): Lista de conversas anteriores, cada uma com:
                - sender: 'ia' ou 'user'
                - message: texto da mensagem
                - timestamp: quando foi enviada
            documentos_analise (dict): AnÃ¡lise dos documentos da negociaÃ§Ã£o com:
                - total_obrigatorios: nÃºmero total de documentos necessÃ¡rios
                - total_recebidos: nÃºmero de documentos jÃ¡ recebidos
                - total_faltantes: nÃºmero de documentos pendentes
                - documentos_faltantes: lista de documentos que faltam
                - progresso_percentual: % de conclusÃ£o
                
        Returns:
            dict: Resultado da anÃ¡lise com:
                - resumo: Resumo do contexto atual da conversa
                - proxima_mensagem: Texto sugerido para prÃ³xima mensagem
                - contexto: SituaÃ§Ã£o atual (ex: "aguardando_documentos", "documentos_completos")
                
        Exemplo:
            >>> conversas = [
                    {"sender": "user", "message": "Bom dia, enviei o RG"},
                    {"sender": "ia", "message": "Recebi! Falta comprovante de renda"}
                ]
            >>> docs = {
                    "total_obrigatorios": 3,
                    "total_recebidos": 1,
                    "documentos_faltantes": [{"name": "Comprovante de Renda"}]
                }
            >>> resultado = analisar_conversas_com_gpt(conversas, docs)
            >>> print(resultado["proxima_mensagem"])
            "Por favor, envie seu comprovante de renda para continuarmos."
        """
        try:
            # Preparar histÃ³rico de conversas para anÃ¡lise
            historico = []
            for conversa in conversas:
                papel = "assistant" if conversa['sender'] == 'ia' else "user"
                historico.append(f"{papel.upper()}: {conversa['message']}")
            
            # ValidaÃ§Ã£o e acesso seguro aos dados de documentos
            total_obrigatorios = documentos_analise.get('total_obrigatorios', 0)
            total_recebidos = documentos_analise.get('total_recebidos', 0)
            total_faltantes = documentos_analise.get('total_faltantes', 0)
            progresso_percentual = documentos_analise.get('progresso_percentual', 0.0)
            documentos_faltantes = documentos_analise.get('documentos_faltantes', [])
            documentos_recebidos = documentos_analise.get('documentos_recebidos', [])
            
            logger.info(f"ğŸ“Š Analisando: {total_recebidos}/{total_obrigatorios} documentos ({progresso_percentual:.1f}%)")
            
            # Preparar lista de documentos faltantes de forma segura
            docs_faltantes_lista = []
            for doc in documentos_faltantes:
                nome = doc.get('name', 'Documento nÃ£o identificado')
                descricao = doc.get('description', 'Sem descriÃ§Ã£o')
                docs_faltantes_lista.append(f"ğŸ“„ *{nome}* - {descricao}")
            
            # Preparar lista de documentos recebidos
            docs_recebidos_lista = []
            for doc in documentos_recebidos:
                nome_tipo = doc.get('ai_document_types', {}).get('name', 'Documento')
                docs_recebidos_lista.append(f"âœ… {nome_tipo}")
            
            # Preparar informaÃ§Ãµes sobre documentos
            docs_info = f"""
            DOCUMENTOS OBRIGATÃ“RIOS: {total_obrigatorios}
            DOCUMENTOS RECEBIDOS: {total_recebidos}
            DOCUMENTOS FALTANTES: {total_faltantes}
            PROGRESSO: {progresso_percentual:.1f}%
            
            DOCUMENTOS JÃ RECEBIDOS:
            {chr(10).join(docs_recebidos_lista) if docs_recebidos_lista else "Nenhum documento recebido ainda"}
            
            DOCUMENTOS FALTANTES:
            {chr(10).join(docs_faltantes_lista) if docs_faltantes_lista else "Nenhum documento faltante"}
            """
            
            # Determinar contexto atual baseado nos dados
            if total_obrigatorios == 0:
                contexto_atual = "sem_documentos_definidos"
            elif total_faltantes == 0 and total_recebidos > 0:
                contexto_atual = "documentos_completos"
            elif total_recebidos > 0:
                contexto_atual = "aguardando_documentos"
            else:
                contexto_atual = "iniciando_coleta"
            
            # Prompt para GPT-4
            prompt = f"""
            VocÃª Ã© um assistente IA especializado em negociaÃ§Ãµes imobiliÃ¡rias. Analise o histÃ³rico de conversas abaixo e as informaÃ§Ãµes sobre documentos para:

            1. RESUMIR onde parou a conversa
            2. IDENTIFICAR o que o cliente precisa fazer agora
            3. SUGERIR a prÃ³xima mensagem apropriada

            HISTÃ“RICO DE CONVERSAS ({len(historico)} mensagens):
            {chr(10).join(historico) if historico else "Nenhuma conversa anterior"}

            SITUAÃ‡ÃƒO DOS DOCUMENTOS:
            {docs_info}

            CONTEXTO ATUAL: {contexto_atual}

            INSTRUÃ‡Ã•ES:
            - Seja cordial e profissional
            - Se faltam documentos, mencione ESPECIFICAMENTE quais documentos estÃ£o faltando com suas descriÃ§Ãµes
                        - Use formataÃ§Ã£o com quebras de linha para melhor legibilidade no WhatsApp:
              "Recebi seu RG âœ…
              
              Ainda preciso de:
              ğŸ“„ *Comprovante de Renda* - Ãºltimos 3 holerites
              ğŸ  *Comprovante de ResidÃªncia* - conta de luz/Ã¡gua  
              ğŸ“‹ *CertidÃ£o de Nascimento/Casamento* - estado civil
              
              Me peÃ§a para enviar documentos que inicio a sequÃªncia de envios com vocÃª! ğŸ“„"
            - Se todos os documentos foram enviados, informe o prÃ³ximo passo
            - Mantenha o tom conversacional e amigÃ¡vel
            - Use emojis para deixar mais amigÃ¡vel
            - Use quebras de linha para separar as informaÃ§Ãµes
            - Se nÃ£o hÃ¡ conversas anteriores, seja acolhedor e explique o processo

            Responda em JSON com:
            - "resumo": Resumo do contexto atual
            - "proxima_mensagem": Mensagem para enviar ao cliente
            - "contexto": SituaÃ§Ã£o atual (ex: "aguardando_documentos", "documentos_completos", "iniciando_conversa")
            """
            
            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um assistente especializado em anÃ¡lise de conversas imobiliÃ¡rias. Responda sempre em JSON vÃ¡lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # Processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            
            # Tentar fazer parse do JSON
            try:
                resultado = json.loads(resposta_texto)
                logger.info(f"âœ… AnÃ¡lise GPT-4 concluÃ­da com sucesso")
                return resultado
            except json.JSONDecodeError:
                logger.warning(f"âš ï¸ Resposta GPT-4 nÃ£o Ã© JSON vÃ¡lido: {resposta_texto[:200]}...")
                
                # Tentar extrair mensagem Ãºtil do texto mal formado
                mensagem_limpa = resposta_texto
                
                # Se contÃ©m estrutura JSON parcial, tentar extrair a mensagem
                if '"proxima_mensagem"' in resposta_texto:
                    try:
                        # Buscar o conteÃºdo da proxima_mensagem
                        match = re.search(r'"proxima_mensagem":\s*"([^"]*)"', resposta_texto)
                        if match:
                            mensagem_limpa = match.group(1)
                            logger.info(f"âœ… Mensagem extraÃ­da do JSON parcial")
                        else:
                            # Fallback: usar texto apÃ³s dois pontos
                            if ':"' in resposta_texto:
                                mensagem_limpa = resposta_texto.split(':"')[1].split('"')[0]
                    except Exception as e_regex:
                        logger.warning(f"âš ï¸ Erro ao extrair mensagem: {e_regex}")
                        # Usar mensagem padrÃ£o se falhar
                        mensagem_limpa = "Analisei sua situaÃ§Ã£o e vou continuar te ajudando com os prÃ³ximos passos!"
                else:
                    # Se nÃ£o tem estrutura JSON, usar o texto direto mas limitar tamanho
                    mensagem_limpa = resposta_texto[:200] if len(resposta_texto) > 200 else resposta_texto
                    # Remover caracteres JSON comuns que possam aparecer
                    mensagem_limpa = mensagem_limpa.replace('{"', '').replace('"}', '').replace('\\n', '\n')
                
                return {
                    "resumo": "AnÃ¡lise concluÃ­da com texto nÃ£o estruturado",
                    "proxima_mensagem": mensagem_limpa,
                    "contexto": "analise_texto_livre"
                }
            
        except Exception as e:
            logger.error(f"âŒ Erro na anÃ¡lise GPT-4: {str(e)}")
            return {
                "resumo": f"Erro na anÃ¡lise: {str(e)}",
                "proxima_mensagem": "Vou analisar sua situaÃ§Ã£o e retorno em breve. Obrigado pela paciÃªncia!",
                "contexto": "erro_analise"
            }

    def interpretar_intencao_mensagem(self, mensagem: str, remetente: str = None) -> Dict[str, Any]:
        """
        Interpretador inteligente para detectar intenÃ§Ãµes em mensagens usando GPT
        
        Esta funÃ§Ã£o Ã© o INTERPRETADOR CENTRAL que processa TODAS as mensagens
        antes do fluxo principal, identificando:
        - SaudaÃ§Ãµes (oi, olÃ¡, bom dia) â†’ Primeira mensagem da Bia
        - SolicitaÃ§Ãµes de menu (menu, opÃ§Ãµes) â†’ Menu apropriado por tipo de usuÃ¡rio
        - Conversas normais â†’ Continua fluxo original
        
        Args:
            mensagem (str): Texto da mensagem recebida do usuÃ¡rio
            remetente (str, optional): NÃºmero do telefone (para contexto futuro)
            
        Returns:
            Dict com anÃ¡lise da intenÃ§Ã£o:
                - intencao: "saudacao" | "menu" | "conversa_normal" | "duvida_tecnica"
                - confianca: 0.0-1.0 (nÃ­vel de certeza da IA)
                - bypass_fluxo: True se deve interceptar, False se continua normal
                - contexto: "primeira_interacao" | "usuario_conhecido"
                - acao_sugerida: "primeira_mensagem" | "enviar_menu" | "continuar_fluxo"
        
        Exemplo de uso:
            >>> interpretacao = service.interpretar_intencao_mensagem("oi, tudo bem?")
            >>> print(interpretacao["intencao"])  # "saudacao"
            >>> print(interpretacao["bypass_fluxo"])  # True
        """
        try:
            logger.info(f"ğŸ§  Interpretando intenÃ§Ã£o da mensagem: {mensagem[:50]}...")
            
            # Prompt especializado para detectar intenÃ§Ãµes
            prompt = f"""Analise esta mensagem do WhatsApp e identifique a intenÃ§Ã£o do usuÃ¡rio:

MENSAGEM: "{mensagem}"

Classifique a intenÃ§Ã£o como:

1. "saudacao" - Se contÃ©m cumprimentos como: oi, olÃ¡, bom dia, boa tarde, boa noite, hey, e aÃ­, tudo bem, como vai, etc.

2. "menu" - Se solicita navegaÃ§Ã£o como: menu, opÃ§Ãµes, voltar menu, menu inicial, mostrar opÃ§Ãµes, escolhas, navegar, etc.

3. "conversa_normal" - Se contÃ©m: CPF, nÃºmeros, perguntas especÃ­ficas, documentos, informaÃ§Ãµes pessoais

4. "duvida_tecnica" - Se contÃ©m perguntas sobre: locaÃ§Ã£o, processos, contratos, documentaÃ§Ã£o, anÃ¡lise, negociaÃ§Ã£o

IMPORTANTE:
- Alta confianÃ§a (>0.8) apenas se for CLARAMENTE uma saudaÃ§Ã£o ou solicitaÃ§Ã£o de menu
- MÃ©dia confianÃ§a (0.5-0.8) se houver dÃºvida
- Baixa confianÃ§a (<0.5) se for ambÃ­guo

Responda APENAS em JSON vÃ¡lido:
{{
  "intencao": "saudacao|menu|conversa_normal|duvida_tecnica",
  "confianca": 0.0,
  "bypass_fluxo": true/false,
  "contexto": "primeira_interacao|usuario_conhecido",
  "acao_sugerida": "primeira_mensagem|enviar_menu|continuar_fluxo"
}}"""

            # Chamada para GPT com configuraÃ§Ãµes otimizadas
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """VocÃª Ã© um analisador especializado em intenÃ§Ãµes de mensagens para um sistema de atendimento imobiliÃ¡rio.

Sua funÃ§Ã£o Ã© identificar com precisÃ£o a intenÃ§Ã£o real do usuÃ¡rio:

- SAUDAÃ‡Ã•ES: Cumprimentos gerais e iniciais de conversa
- MENU: SolicitaÃ§Ãµes explÃ­citas de navegaÃ§Ã£o ou opÃ§Ãµes
- CONVERSA_NORMAL: InformaÃ§Ãµes especÃ­ficas como CPF, dados pessoais
- DUVIDA_TECNICA: Perguntas sobre processos, contratos, locaÃ§Ã£o

Seja conservador: apenas classifique como "saudacao" ou "menu" se tiver ALTA CERTEZA.
Caso contrÃ¡rio, use "conversa_normal" para manter o fluxo original funcionando.

SEMPRE retorne JSON vÃ¡lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consistÃªncia
                max_tokens=150    # Resposta curta e objetiva
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ğŸ¤– Resposta GPT: {resposta_texto[:100]}...")
            
            try:
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar campos obrigatÃ³rios
                campos_obrigatorios = ["intencao", "confianca", "bypass_fluxo", "acao_sugerida"]
                for campo in campos_obrigatorios:
                    if campo not in resultado:
                        raise ValueError(f"Campo obrigatÃ³rio ausente: {campo}")
                
                # Ajustar bypass_fluxo baseado na intenÃ§Ã£o e confianÃ§a
                if resultado["confianca"] < 0.7:
                    resultado["bypass_fluxo"] = False
                    resultado["acao_sugerida"] = "continuar_fluxo"
                else:
                    # Para saudaÃ§Ãµes e menu com alta confianÃ§a, sempre fazer bypass
                    if resultado["intencao"] in ["saudacao", "menu"]:
                        resultado["bypass_fluxo"] = True
                        if resultado["intencao"] == "saudacao":
                            resultado["acao_sugerida"] = "primeira_mensagem"
                        elif resultado["intencao"] == "menu":
                            resultado["acao_sugerida"] = "enviar_menu"
                
                logger.info(f"âœ… IntenÃ§Ã£o detectada: {resultado['intencao']} (confianÃ§a: {resultado['confianca']})")
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"âš ï¸ Erro ao processar JSON do GPT: {e}")
                # Fallback: continuar fluxo normal
                return {
                    "intencao": "conversa_normal",
                    "confianca": 0.0,
                    "bypass_fluxo": False,
                    "contexto": "usuario_conhecido", 
                    "acao_sugerida": "continuar_fluxo",
                    "erro": "json_parse_error"
                }
                
        except Exception as e:
            logger.error(f"âŒ Erro crÃ­tico no interpretador de intenÃ§Ãµes: {str(e)}")
            # Fallback seguro: sempre continuar fluxo normal em caso de erro
            return {
                "intencao": "conversa_normal",
                "confianca": 0.0,
                "bypass_fluxo": False,
                "contexto": "usuario_conhecido",
                "acao_sugerida": "continuar_fluxo",
                "erro": str(e)
            }


    def validar_dado_cliente(self, tipo_dado: str, valor: str) -> Dict[str, Any]:
        """
        Valida dados do cliente coletados durante processo de fechamento usando GPT
        
        Esta funÃ§Ã£o usa IA para validar se os dados fornecidos pelo colaborador
        sÃ£o vÃ¡lidos para um processo de locaÃ§Ã£o imobiliÃ¡ria.
        
        Args:
            tipo_dado (str): Tipo do dado a validar ("nome" | "telefone")
            valor (str): Valor fornecido pelo colaborador para validaÃ§Ã£o
            
        Returns:
            Dict com resultado da validaÃ§Ã£o:
                - valido: True se dado Ã© vÃ¡lido, False se invÃ¡lido
                - valor_corrigido: Valor formatado/corrigido se necessÃ¡rio
                - motivo_erro: ExplicaÃ§Ã£o se invÃ¡lido
                - sugestao: SugestÃ£o de correÃ§Ã£o se aplicÃ¡vel
        
        Exemplos de uso:
            >>> resultado = service.validar_dado_cliente("nome", "JoÃ£o Silva")
            >>> print(resultado["valido"])  # True
            
            >>> resultado = service.validar_dado_cliente("telefone", "11999999999")
            >>> print(resultado["valor_corrigido"])  # "(11) 99999-9999"
        """
        try:
            logger.info(f"ğŸ” Validando {tipo_dado}: {valor[:30]}...")
            
            if tipo_dado == "nome":
                # Prompt para validaÃ§Ã£o de nome
                prompt = f"""Analise se este Ã© um nome vÃ¡lido para um cliente de locaÃ§Ã£o imobiliÃ¡ria:

NOME: "{valor}"

CritÃ©rios FLEXÃVEIS de validaÃ§Ã£o:
1. Deve conter pelo menos 2 palavras (nome + sobrenome)
2. Deve usar caracteres alfabÃ©ticos (permitir acentos, espaÃ§os)
3. NÃ£o deve conter nÃºmeros ou sÃ­mbolos especiais
4. Deve parecer um nome real de pessoa
5. Aceitar nomes compostos, duplos, estrangeiros

Exemplos VÃLIDOS: "JoÃ£o Silva", "Maria Santos", "JosÃ© da Silva", "Ana Beatriz", "Carlos Eduardo", "Andreia Robe", "Maria JosÃ©", "JoÃ£o Pedro"
Exemplos INVÃLIDOS: "JoÃ£o", "123", "abc", "JoÃ£o123", "@#$", "X Y", "A B"

IMPORTANTE: Seja FLEXÃVEL com nomes reais. Se parece um nome de pessoa vÃ¡lido com pelo menos 2 palavras, ACEITE.

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Nome formatado corretamente",
  "motivo_erro": "ExplicaÃ§Ã£o se invÃ¡lido",
  "sugestao": "SugestÃ£o de correÃ§Ã£o se necessÃ¡rio"
}}"""

            elif tipo_dado == "telefone":
                # Prompt para validaÃ§Ã£o de telefone
                prompt = f"""Analise se este Ã© um telefone vÃ¡lido brasileiro:

TELEFONE: "{valor}"

CritÃ©rios de validaÃ§Ã£o:
1. Deve ter 10 ou 11 dÃ­gitos (com DDD)
2. DDD vÃ¡lido brasileiro (11-99)
3. NÃºmero de celular ou fixo vÃ¡lido
4. Pode ter ou nÃ£o formataÃ§Ã£o
5. NÃ£o deve conter letras

Exemplos VÃLIDOS: "11999999999", "(11) 99999-9999", "1133334444"
Exemplos INVÃLIDOS: "999999999", "abc", "123", "00999999999"

Se vÃ¡lido, formate como: (XX) XXXXX-XXXX para celular ou (XX) XXXX-XXXX para fixo

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Telefone formatado: (XX) XXXXX-XXXX",
  "motivo_erro": "ExplicaÃ§Ã£o se invÃ¡lido",
  "sugestao": "SugestÃ£o de correÃ§Ã£o se necessÃ¡rio"
}}"""

            else:
                return {
                    "valido": False,
                    "motivo_erro": f"Tipo de dado nÃ£o suportado: {tipo_dado}",
                    "sugestao": "Use 'nome' ou 'telefone'"
                }

            # Chamada para GPT com configuraÃ§Ãµes de validaÃ§Ã£o
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": """VocÃª Ã© um validador especializado em dados de clientes para processos imobiliÃ¡rios.

Sua funÃ§Ã£o Ã© verificar se os dados fornecidos sÃ£o vÃ¡lidos e Ãºteis para um processo de locaÃ§Ã£o.

Seja rigoroso na validaÃ§Ã£o:
- Nomes devem ser completos e reais
- Telefones devem ser brasileiros vÃ¡lidos
- Sempre formate corretamente os dados vÃ¡lidos
- ForneÃ§a explicaÃ§Ãµes claras para dados invÃ¡lidos

SEMPRE retorne JSON vÃ¡lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consistÃªncia na validaÃ§Ã£o
                max_tokens=200
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ğŸ¤– ValidaÃ§Ã£o GPT: {resposta_texto[:100]}...")
            
            try:
                # Parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar campos obrigatÃ³rios
                if "valido" not in resultado:
                    raise ValueError("Campo 'valido' ausente na resposta")
                
                # Adicionar informaÃ§Ãµes de contexto
                resultado.update({
                    "tipo_dado": tipo_dado,
                    "valor_original": valor,
                    "timestamp_validacao": "now"
                })
                
                status = "âœ… VÃLIDO" if resultado["valido"] else "âŒ INVÃLIDO"
                logger.info(f"{status} - {tipo_dado}: {valor[:20]}...")
                
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"âš ï¸ Erro ao processar JSON de validaÃ§Ã£o: {e}")
                # Fallback: considerar invÃ¡lido se nÃ£o conseguir processar
                return {
                    "valido": False,
                    "motivo_erro": "Erro interno na validaÃ§Ã£o",
                    "sugestao": f"Tente novamente com um {tipo_dado} mais claro",
                    "erro_processamento": str(e)
                }
                
        except Exception as e:
            logger.error(f"âŒ Erro crÃ­tico na validaÃ§Ã£o de dados: {str(e)}")
            # Fallback seguro: sempre rejeitar em caso de erro
            return {
                "valido": False,
                "motivo_erro": "Erro tÃ©cnico na validaÃ§Ã£o",
                "sugestao": f"Tente novamente fornecendo o {tipo_dado}",
                "erro_critico": str(e)
            }

    def responder_duvida_locacao(self, duvida: str, contexto_colaborador: dict = None) -> Dict[str, Any]:
        """
        IA especializada em responder dÃºvidas sobre negociaÃ§Ã£o de locaÃ§Ã£o para colaboradores
        
        Esta funÃ§Ã£o Ã© chamada quando um colaborador seleciona "Usar IA para DÃºvidas" no menu
        e envia uma pergunta relacionada a processos de locaÃ§Ã£o, documentos, negociaÃ§Ã£o, etc.
        
        Args:
            duvida (str): Pergunta/dÃºvida do colaborador sobre locaÃ§Ã£o
            contexto_colaborador (dict, optional): Dados do colaborador (setor, nome, etc.)
            
        Returns:
            Dict: Resposta estruturada com:
                - resposta: Texto da resposta especializada
                - categoria: Categoria da dÃºvida (documentos, processo, juridico, etc.)
                - confianca: NÃ­vel de confianÃ§a da resposta (alto/medio/baixo)
                - sugestoes_extras: SugestÃµes adicionais se aplicÃ¡vel
                
        Exemplo:
            >>> resultado = responder_duvida_locacao("Como validar comprovante de renda?")
            >>> print(resultado["resposta"])
            "Para validar comprovante de renda, vocÃª deve verificar..."
        """
        try:
            logger.info(f"ğŸ¤– Processando dÃºvida de locaÃ§Ã£o: {duvida[:50]}...")
            
            # Extrair informaÃ§Ãµes do colaborador se disponÃ­vel
            nome_colaborador = "Colaborador"
            setor_colaborador = "NÃ£o informado"
            
            if contexto_colaborador:
                nome_colaborador = contexto_colaborador.get('nome', 'Colaborador')
                setor_colaborador = contexto_colaborador.get('setor', 'NÃ£o informado')
            
            # Prompt especializado em negociaÃ§Ã£o de locaÃ§Ã£o
            prompt_sistema = """
            VocÃª Ã© um ESPECIALISTA em NEGOCIAÃ‡ÃƒO DE LOCAÃ‡ÃƒO IMOBILIÃRIA e assistente para colaboradores da Toca ImÃ³veis.

            ESPECIALIDADES:
            ğŸ  Processos de locaÃ§Ã£o sem fiador
            ğŸ“„ DocumentaÃ§Ã£o necessÃ¡ria (RG, CPF, comprovantes)
            ğŸ’° AnÃ¡lise de renda e capacidade financeira
            ğŸ“‹ Contratos e termos legais
            ğŸ” ValidaÃ§Ã£o de documentos
            ğŸ‘¥ Relacionamento com clientes
            âš–ï¸ Aspectos jurÃ­dicos bÃ¡sicos
            ğŸ“Š Fluxos e procedimentos internos

            INSTRUÃ‡Ã•ES:
            - Responda de forma PRÃTICA e OBJETIVA
            - Use linguagem PROFISSIONAL mas ACESSÃVEL
            - ForneÃ§a PASSOS CONCRETOS quando aplicÃ¡vel
            - Mencione DOCUMENTOS ESPECÃFICOS quando necessÃ¡rio
            - Use EMOJIS para organizar a informaÃ§Ã£o
            - Se nÃ£o souber algo especÃ­fico da Toca ImÃ³veis, seja transparente
            - Foque em SOLUÃ‡Ã•ES PRÃTICAS para o dia a dia

            FORMATO DA RESPOSTA:
            - Use quebras de linha para facilitar leitura no WhatsApp
            - Organize em tÃ³picos quando necessÃ¡rio
            - Seja direto e evite textos muito longos
            """

            prompt_usuario = f"""
            CONTEXTO DO COLABORADOR:
            ğŸ‘¤ Nome: {nome_colaborador}
            ğŸ¢ Setor: {setor_colaborador}

            DÃšVIDA:
            {duvida}

            Responda esta dÃºvida de forma especializada, considerando que Ã© um colaborador da Toca ImÃ³veis que precisa de orientaÃ§Ã£o prÃ¡tica para seu trabalho diÃ¡rio.

            Formate sua resposta em JSON com:
            - "resposta": Resposta detalhada e prÃ¡tica para a dÃºvida
            - "categoria": Categoria da dÃºvida (documentos|processo|juridico|relacionamento|financeiro|outros)
            - "confianca": NÃ­vel de confianÃ§a da resposta (alto|medio|baixo)
            - "sugestoes_extras": Array com sugestÃµes adicionais ou prÃ³ximos passos (mÃ¡ximo 3 sugestÃµes)
            """

            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": prompt_sistema},
                    {"role": "user", "content": prompt_usuario}
                ],
                temperature=0.3,  # Baixa temperatura para respostas mais consistentes
                max_tokens=800,   # EspaÃ§o suficiente para resposta detalhada
                top_p=0.9
            )

            # Extrair e processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            
            try:
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_texto)
                
                # Validar estrutura da resposta
                if not all(key in resultado for key in ['resposta', 'categoria', 'confianca']):
                    raise ValueError("JSON nÃ£o contÃ©m todas as chaves necessÃ¡rias")
                
                # Garantir que sugestoes_extras seja uma lista
                if 'sugestoes_extras' not in resultado:
                    resultado['sugestoes_extras'] = []
                elif not isinstance(resultado['sugestoes_extras'], list):
                    resultado['sugestoes_extras'] = [str(resultado['sugestoes_extras'])]
                
                logger.info(f"âœ… DÃºvida processada - Categoria: {resultado['categoria']}")
                logger.info(f"ğŸ¯ ConfianÃ§a: {resultado['confianca']}")
                
                return {
                    "sucesso": True,
                    "resposta": resultado['resposta'],
                    "categoria": resultado['categoria'],
                    "confianca": resultado['confianca'],
                    "sugestoes_extras": resultado['sugestoes_extras'],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador
                }
                
            except (json.JSONDecodeError, ValueError) as e:
                # Se JSON invÃ¡lido, usar resposta como texto simples
                logger.warning(f"âš ï¸ Resposta nÃ£o Ã© JSON vÃ¡lido: {str(e)}")
                
                # Limpar a resposta e usar como texto
                resposta_limpa = resposta_texto.replace('```json', '').replace('```', '').strip()
                
                # Tentar extrair pelo menos a resposta principal
                if '"resposta"' in resposta_limpa:
                    match = re.search(r'"resposta":\s*"([^"]*)"', resposta_limpa)
                    if match:
                        resposta_limpa = match.group(1).replace('\\n', '\n')
                
                return {
                    "sucesso": True,
                    "resposta": resposta_limpa,
                    "categoria": "geral",
                    "confianca": "medio",
                    "sugestoes_extras": ["Posso esclarecer mais detalhes se precisar"],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador,
                    "aviso": "Resposta processada como texto livre"
                }
                
        except Exception as e:
            logger.error(f"âŒ Erro ao processar dÃºvida de locaÃ§Ã£o: {str(e)}")
            
            return {
                "sucesso": False,
                "resposta": "Desculpe, tive um problema tÃ©cnico ao processar sua dÃºvida. Pode reformular sua pergunta ou tentar novamente em alguns instantes?",
                "categoria": "erro",
                "confianca": "baixo",
                "sugestoes_extras": [
                    "Tente reformular a pergunta",
                    "Seja mais especÃ­fico sobre o tema",
                    "Verifique se Ã© uma dÃºvida sobre locaÃ§Ã£o"
                ],
                "colaborador": nome_colaborador,
                "setor": setor_colaborador,
                "erro": str(e)
            } 

    def analisar_e_limpar_conversa_json(self, conversa_json: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ§  NOVA FUNÃ‡ÃƒO: Usa OpenAI para analisar e limpar JSON de conversa
        
        Funcionalidades:
        - Remove mensagens duplicadas
        - Remove logs tÃ©cnicos e do sistema
        - Formata mensagens de menu naturalmente
        - Remove detalhes tÃ©cnicos como "(row_id: iniciar_fechamento)"
        - Prepara JSON otimizado para banco de dados
        
        Args:
            conversa_json (Dict): JSON da conversa original
            
        Returns:
            Dict: JSON limpo e otimizado
        """
        try:
            logger.info("ğŸ§  Iniciando anÃ¡lise e limpeza do JSON da conversa com OpenAI...")
            
            # Extrair mensagens para anÃ¡lise
            mensagens_originais = conversa_json.get('messages', [])
            
            if not mensagens_originais:
                logger.warning("âš ï¸ Nenhuma mensagem encontrada para analisar")
                return conversa_json
            
            # Preparar dados para OpenAI
            mensagens_para_analise = []
            for i, msg in enumerate(mensagens_originais):
                mensagens_para_analise.append({
                    "index": i,
                    "id": msg.get('id'),
                    "timestamp": msg.get('timestamp'),
                    "sender": msg.get('sender'),
                    "content": msg.get('content', '')[:500],  # Limitar tamanho
                    "message_type": msg.get('message_type'),
                    "phase": msg.get('phase')
                })
            
            # Extrair dados dos participantes para detecÃ§Ã£o inteligente
            participants = conversa_json.get('participants', {})
            client_data = participants.get('client', {})
            client_cpf = client_data.get('cpf', '')
            client_email = client_data.get('email', '')
            
            # Prompt para OpenAI com detecÃ§Ã£o inteligente
            prompt_analise = f"""
Analise esta conversa de WhatsApp e identifique:

1. **MENSAGENS DUPLICADAS**: Mensagens idÃªnticas ou muito similares
2. **LOGS TÃ‰CNICOS**: Mensagens que sÃ£o logs do sistema (ex: "ğŸ“„ CPF PROCESSADO", detalhes tÃ©cnicos)
3. **MENSAGENS DO SISTEMA**: sender="system" que nÃ£o agregam valor
4. **FORMATAÃ‡ÃƒO DE MENUS**: Mensagens com "(row_id: ...)" devem ser naturalizadas
5. **MENSAGENS PERDIDAS**: Detectar se faltam respostas do cliente baseado no fluxo

**MENSAGENS DA CONVERSA:**
{json.dumps(mensagens_para_analise, ensure_ascii=False, indent=2)}

**DADOS DO CLIENTE (para detecÃ§Ã£o inteligente):**
- CPF: {client_cpf}
- Email: {client_email}

**DETECÃ‡ÃƒO INTELIGENTE (REGRA CRÃTICA):**

EXEMPLO DE PROBLEMA:
1. msg_003: IA diz "preciso do seu CPF"
2. msg_004: IA detalha "Para prosseguir, preciso do seu CPF: (nÃºmeros)"
3. msg_005: IA diz "Digite seu e-mail"  â† PROBLEMA! Cliente nÃ£o respondeu CPF!

REGRA: Se IA pede CPF e prÃ³xima mensagem Ã© IA pedindo EMAIL (sem resposta do cliente), entÃ£o INSERIR:
{{
  "inserir_apos_index": [Ã­ndice da mensagem que pede CPF],
  "sender": "cliente", 
  "content": "{client_cpf}",
  "motivo": "Resposta de CPF perdida detectada"
}}

OUTROS PADRÃ•ES:
- IA pede CPF â†’ IA pede EMAIL = FALTA resposta CPF
- IA pede EMAIL â†’ IA pede DATA = FALTA resposta EMAIL
- IA pede DATA â†’ IA pede CEP = FALTA resposta DATA

**RESPONDA EM JSON:**
{{
  "mensagens_para_manter": [Ã­ndices das mensagens que devem ser mantidas],
  "mensagens_para_remover": [Ã­ndices das mensagens que devem ser removidas],
  "mensagens_para_reformatar": [
    {{
      "index": Ã­ndice,
      "novo_conteudo": "nova versÃ£o sem detalhes tÃ©cnicos"
    }}
  ],
  "mensagens_para_inserir": [
    {{
      "inserir_apos_index": Ã­ndice,
      "sender": "cliente",
      "content": "resposta do cliente",
      "motivo": "mensagem perdida detectada"
    }}
  ],
  "justificativa": "explicaÃ§Ã£o breve das mudanÃ§as"
}}

**REGRAS:**
- Manter TODAS as mensagens essenciais do cliente e IA
- Remover apenas duplicatas Ã³bvias e logs tÃ©cnicos
- Naturalizar menus: "Iniciar Fechamento LocaÃ§Ã£o" (sem row_id)
- INSERIR mensagens perdidas do cliente automaticamente
- Preservar fluxo da conversa
- Ser conservador - na dÃºvida, manter
"""

            # Chamar OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {
                        "role": "system", 
                        "content": """VocÃª Ã© um especialista em anÃ¡lise de conversas de WhatsApp. 

SUA MISSÃƒO ESPECÃFICA: Detectar quando mensagens do cliente estÃ£o perdidas.

PADRÃƒO CRÃTICO A DETECTAR:
- IA pede CPF: "preciso do seu CPF"
- IA pede email: "Digite seu e-mail" (SEM o cliente ter respondido CPF)
- = PROBLEMA! Falta mensagem do cliente com CPF

QUANDO DETECTAR ESSE PADRÃƒO, vocÃª DEVE inserir a mensagem perdida usando os dados dos participants.

Seja PRECISO na detecÃ§Ã£o de fluxos quebrados."""
                    },
                    {
                        "role": "user", 
                        "content": prompt_analise
                    }
                ],
                temperature=0.1,  # Baixa temperatura para consistÃªncia
                max_tokens=2000
            )
            
            # Processar resposta
            resposta_openai = response.choices[0].message.content.strip()
            
            # Limpar resposta removendo markdown
            resposta_limpa = resposta_openai.replace('```json', '').replace('```', '').strip()
            
            try:
                # Tentar parsear JSON da resposta
                analise = json.loads(resposta_limpa)
                logger.info(f"âœ… AnÃ¡lise OpenAI concluÃ­da: {analise.get('justificativa', 'N/A')}")
                
            except json.JSONDecodeError:
                logger.error("âŒ Erro ao parsear resposta JSON da OpenAI")
                logger.error(f"Resposta recebida: {resposta_limpa}")
                return conversa_json
            
            # Aplicar as mudanÃ§as recomendadas
            mensagens_limpas = self._aplicar_limpeza_conversa(
                mensagens_originais, 
                analise,
                conversa_json
            )
            
            # Criar JSON limpo
            conversa_limpa = conversa_json.copy()
            conversa_limpa['messages'] = mensagens_limpas
            
            # Atualizar estatÃ­sticas
            if 'conversation_summary' in conversa_limpa:
                conversa_limpa['conversation_summary']['total_messages'] = len(mensagens_limpas)
                conversa_limpa['conversation_summary']['cleaned_by_ai'] = True
                conversa_limpa['conversation_summary']['original_count'] = len(mensagens_originais)
                conversa_limpa['conversation_summary']['removed_count'] = len(mensagens_originais) - len(mensagens_limpas)
            
            # Adicionar metadata da limpeza
            conversa_limpa['ai_cleaning'] = {
                "cleaned_at": datetime.now().isoformat(),
                "original_message_count": len(mensagens_originais),
                "cleaned_message_count": len(mensagens_limpas),
                "justificativa": analise.get('justificativa', 'Limpeza automÃ¡tica'),
                "removed_indices": analise.get('mensagens_para_remover', []),
                "reformatted_count": len(analise.get('mensagens_para_reformatar', [])),
                "inserted_count": len(analise.get('mensagens_para_inserir', [])),
                "inserted_messages": analise.get('mensagens_para_inserir', [])
            }
            
            logger.info(f"ğŸ§¹ Limpeza concluÃ­da: {len(mensagens_originais)} â†’ {len(mensagens_limpas)} mensagens")
            
            return conversa_limpa
            
        except Exception as e:
            logger.error(f"âŒ Erro na anÃ¡lise/limpeza da conversa: {str(e)}")
            # Em caso de erro, retornar conversa original
            return conversa_json
    
    def _aplicar_limpeza_conversa(self, mensagens_originais: List[Dict], analise: Dict, conversa_json: Dict = None) -> List[Dict]:
        """
        Aplica as recomendaÃ§Ãµes de limpeza da OpenAI
        
        Args:
            mensagens_originais: Lista de mensagens originais
            analise: Resultado da anÃ¡lise OpenAI
            conversa_json: JSON completo da conversa (para dados dos participants)
            
        Returns:
            List: Mensagens limpas
        """
        try:
            mensagens_limpas = []
            indices_para_remover = set(analise.get('mensagens_para_remover', []))
            reformatacoes = {item['index']: item['novo_conteudo'] 
                           for item in analise.get('mensagens_para_reformatar', [])}
            
            # Processar mensagens para inserir
            mensagens_para_inserir = {}
            for item in analise.get('mensagens_para_inserir', []):
                inserir_apos = item.get('inserir_apos_index', -1)
                mensagens_para_inserir[inserir_apos] = item
            
            for i, mensagem in enumerate(mensagens_originais):
                # Pular mensagens marcadas para remoÃ§Ã£o
                if i in indices_para_remover:
                    logger.info(f"ğŸ—‘ï¸ Removendo mensagem {i}: {mensagem.get('content', '')[:50]}...")
                    continue
                
                # Aplicar reformataÃ§Ã£o se necessÃ¡rio
                if i in reformatacoes:
                    mensagem_reformatada = mensagem.copy()
                    mensagem_reformatada['content'] = reformatacoes[i]
                    mensagem_reformatada['ai_reformatted'] = True
                    mensagens_limpas.append(mensagem_reformatada)
                    logger.info(f"âœï¸ Reformatada mensagem {i}: {reformatacoes[i][:50]}...")
                else:
                    # Manter mensagem original
                    mensagens_limpas.append(mensagem)
                
                # Verificar se precisa inserir mensagem apÃ³s esta
                if i in mensagens_para_inserir:
                    nova_mensagem = mensagens_para_inserir[i]
                    
                    # Criar nova mensagem do cliente
                    mensagem_inserida = {
                        "id": f"msg_ai_inserted_{i+1}",
                        "timestamp": mensagem.get('timestamp', ''),
                        "sender": nova_mensagem.get('sender', 'cliente'),
                        "content": nova_mensagem.get('content', ''),
                        "message_type": "text",
                        "metadata": {
                            "receiver_explicit": "ia",
                            "enhanced_method": True,
                            "ai_inserted": True
                        },
                        "sender_specific": "cliente",
                        "receiver_specific": "ia",
                        "interaction_type": "cliente_ia",
                        "phase": mensagem.get('phase', 'ia_cliente'),
                        "ai_inserted": True,
                        "ai_inserted_reason": nova_mensagem.get('motivo', 'Mensagem perdida detectada')
                    }
                    
                    mensagens_limpas.append(mensagem_inserida)
                    logger.info(f"ğŸ”„ Inserida mensagem perdida apÃ³s {i}: {nova_mensagem.get('content', '')[:50]}...")
            
            return mensagens_limpas
            
        except Exception as e:
            logger.error(f"âŒ Erro ao aplicar limpeza: {e}")
            return mensagens_originais 