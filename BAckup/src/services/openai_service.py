import os
import re
import json
from openai import OpenAI
from typing import Dict, Any, List
import logging
from datetime import datetime

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIService:
    """Servi√ßo para integra√ß√£o com OpenAI"""
    
    def __init__(self):
        # Configurar cliente OpenAI
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.company_name = os.getenv('COMPANY_NAME', 'Loca√ß√£o Online')
        
    def interpretar_mensagem(self, mensagem: str) -> Dict[str, Any]:
        """
        Interpreta a mensagem do usu√°rio usando OpenAI
        
        Args:
            mensagem (str): Mensagem do usu√°rio
            
        Returns:
            Dict: Resultado da interpreta√ß√£o com campos:
                - cpf: CPF encontrado ou None
                - novo_usuario: True se for sauda√ß√£o/primeiro contato, False caso contr√°rio
                - solicitar_cpf: True se precisa solicitar CPF
                - mensagem_resposta: Mensagem para enviar ao usu√°rio
        """
        try:
            # Prompt para a OpenAI
            prompt = f"""Como uma Corretora de Loca√ß√£o, analise a mensagem do cliente:

            Mensagem: {mensagem}

            1. Identifique se √© uma sauda√ß√£o ou primeiro contato
            2. Procure por um CPF na mensagem
            3. Determine a pr√≥xima a√ß√£o apropriada

            Retorne apenas um objeto JSON com:
            - cpf: n√∫mero do CPF se encontrado (apenas n√∫meros), ou null se n√£o encontrado
            - novo_usuario: true se for sauda√ß√£o/primeiro contato, false caso contr√°rio
            - solicitar_cpf: true se n√£o encontrou CPF ou false se encontrou
            - mensagem_resposta: mensagem apropriada para o cliente:
              - Se for novo usu√°rio: enviar primeira mensagem padr√£o
              - Se encontrou CPF: apenas confirmar "Ol√°! Confirmo o recebimento do CPF [CPF formatado]."
              - Se n√£o encontrou CPF: solicitar gentilmente
            """
            
            # Fazer chamada para OpenAI com nova sintaxe
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system", 
                        "content": """Voc√™ √© uma Corretora de Loca√ß√£o profissional e eficiente.
                        Seu objetivo √© identificar informa√ß√µes importantes para o processo de loca√ß√£o.
                        Mantenha um tom profissional e direto.
                        Para novos usu√°rios, apresente-se como Bia e solicite o CPF.
                        Para confirma√ß√£o de CPF, apenas confirme o recebimento sem perguntas adicionais.
                        """
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            # Extrair e processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Resposta recebida: {resposta_texto[:100]}...")
            
            try:
                # ‚úÖ CORRE√á√ÉO: Limpeza robusta do JSON
                resposta_limpa = resposta_texto
                
                # Remover markdown se presente
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remover espa√ßos e quebras de linha extras
                resposta_limpa = resposta_limpa.strip()
                
                resultado = json.loads(resposta_limpa)
                logger.info("ü§ñ Interpreta√ß√£o conclu√≠da com sucesso")
                
                return resultado
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON: {e}")
                logger.warning(f"üîç Resposta original: {resposta_texto}")
                
                # ‚úÖ CORRE√á√ÉO: Fallback inteligente
                # Tentar extrair CPF da resposta mesmo com JSON malformado
                cpf_encontrado = None
                if '"cpf"' in resposta_texto:
                    # Buscar padr√£o de CPF na resposta
                    cpf_match = re.search(r'"cpf":\s*"?(\d{11})"?', resposta_texto)
                    if cpf_match:
                        cpf_encontrado = cpf_match.group(1)
                
                # Detectar se √© novo usu√°rio
                novo_usuario = '"novo_usuario": true' in resposta_texto or '"saudacao"' in resposta_texto.lower()
                
                logger.info(f"üîÑ Fallback aplicado - CPF: {cpf_encontrado}, Novo: {novo_usuario}")
                
                return {
                    "cpf": cpf_encontrado,
                    "novo_usuario": novo_usuario,
                    "solicitar_cpf": cpf_encontrado is None,
                    "mensagem_resposta": "Por favor, me envie seu CPF (apenas n√∫meros) para continuarmos o atendimento.",
                    "erro": "json_parse_error_com_fallback"
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao interpretar mensagem: {str(e)}")
            return {
                "cpf": None,
                "novo_usuario": False,
                "solicitar_cpf": True,
                "mensagem_resposta": "Por favor, me envie seu CPF (apenas n√∫meros) para continuarmos o atendimento."
            } 

    def analisar_conversas_com_gpt(self, conversas: List[dict], documentos_analise: dict) -> dict:
        """
        Analisa o hist√≥rico de conversas e documentos de uma negocia√ß√£o usando GPT-4 para gerar uma resposta contextual.
        
        Args:
            conversas (List[dict]): Lista de conversas anteriores, cada uma com:
                - sender: 'ia' ou 'user'
                - message: texto da mensagem
                - timestamp: quando foi enviada
            documentos_analise (dict): An√°lise dos documentos da negocia√ß√£o com:
                - total_obrigatorios: n√∫mero total de documentos necess√°rios
                - total_recebidos: n√∫mero de documentos j√° recebidos
                - total_faltantes: n√∫mero de documentos pendentes
                - documentos_faltantes: lista de documentos que faltam
                - progresso_percentual: % de conclus√£o
                
        Returns:
            dict: Resultado da an√°lise com:
                - resumo: Resumo do contexto atual da conversa
                - proxima_mensagem: Texto sugerido para pr√≥xima mensagem
                - contexto: Situa√ß√£o atual (ex: "aguardando_documentos", "documentos_completos")
                
        Exemplo:
            >>> conversas = [
                    {"sender": "user", "message": "Bom dia, enviei o RG"},
                    {"sender": "ia", "message": "Recebi! Falta comprovante de renda"}
                ]
            >>> docs = {
                    "total_obrigatorios": 3,
                    "total_recebidos": 1,
                    "documentos_faltantes": [{"name": "Comprovante de Renda"}]
                }
            >>> resultado = analisar_conversas_com_gpt(conversas, docs)
            >>> print(resultado["proxima_mensagem"])
            "Por favor, envie seu comprovante de renda para continuarmos."
        """
        try:
            # Preparar hist√≥rico de conversas para an√°lise
            historico = []
            for conversa in conversas:
                papel = "assistant" if conversa['sender'] == 'ia' else "user"
                historico.append(f"{papel.upper()}: {conversa['message']}")
            
            # Valida√ß√£o e acesso seguro aos dados de documentos
            total_obrigatorios = documentos_analise.get('total_obrigatorios', 0)
            total_recebidos = documentos_analise.get('total_recebidos', 0)
            total_faltantes = documentos_analise.get('total_faltantes', 0)
            progresso_percentual = documentos_analise.get('progresso_percentual', 0.0)
            documentos_faltantes = documentos_analise.get('documentos_faltantes', [])
            documentos_recebidos = documentos_analise.get('documentos_recebidos', [])
            
            logger.info(f"üìä Analisando: {total_recebidos}/{total_obrigatorios} documentos ({progresso_percentual:.1f}%)")
            
            # Preparar lista de documentos faltantes de forma segura
            docs_faltantes_lista = []
            for doc in documentos_faltantes:
                nome = doc.get('name', 'Documento n√£o identificado')
                descricao = doc.get('description', 'Sem descri√ß√£o')
                docs_faltantes_lista.append(f"üìÑ *{nome}* - {descricao}")
            
            # Preparar lista de documentos recebidos
            docs_recebidos_lista = []
            for doc in documentos_recebidos:
                nome_tipo = doc.get('ai_document_types', {}).get('name', 'Documento')
                docs_recebidos_lista.append(f"‚úÖ {nome_tipo}")
            
            # Preparar informa√ß√µes sobre documentos
            docs_info = f"""
            DOCUMENTOS OBRIGAT√ìRIOS: {total_obrigatorios}
            DOCUMENTOS RECEBIDOS: {total_recebidos}
            DOCUMENTOS FALTANTES: {total_faltantes}
            PROGRESSO: {progresso_percentual:.1f}%
            
            DOCUMENTOS J√Å RECEBIDOS:
            {chr(10).join(docs_recebidos_lista) if docs_recebidos_lista else "Nenhum documento recebido ainda"}
            
            DOCUMENTOS FALTANTES:
            {chr(10).join(docs_faltantes_lista) if docs_faltantes_lista else "Nenhum documento faltante"}
            """
            
            # Determinar contexto atual baseado nos dados
            if total_obrigatorios == 0:
                contexto_atual = "sem_documentos_definidos"
            elif total_faltantes == 0 and total_recebidos > 0:
                contexto_atual = "documentos_completos"
            elif total_recebidos > 0:
                contexto_atual = "aguardando_documentos"
            else:
                contexto_atual = "iniciando_coleta"
            
            # Prompt para GPT-4
            prompt = f"""
            Voc√™ √© um assistente IA especializado em negocia√ß√µes imobili√°rias. Analise o hist√≥rico de conversas abaixo e as informa√ß√µes sobre documentos para:

            1. RESUMIR onde parou a conversa
            2. IDENTIFICAR o que o cliente precisa fazer agora
            3. SUGERIR a pr√≥xima mensagem apropriada

            HIST√ìRICO DE CONVERSAS ({len(historico)} mensagens):
            {chr(10).join(historico) if historico else "Nenhuma conversa anterior"}

            SITUA√á√ÉO DOS DOCUMENTOS:
            {docs_info}

            CONTEXTO ATUAL: {contexto_atual}

            INSTRU√á√ïES:
            - Seja cordial e profissional
            - Se faltam documentos, mencione ESPECIFICAMENTE quais documentos est√£o faltando com suas descri√ß√µes
                        - Use formata√ß√£o com quebras de linha para melhor legibilidade no WhatsApp:
              "Recebi seu RG ‚úÖ
              
              Ainda preciso de:
              üìÑ *Comprovante de Renda* - √∫ltimos 3 holerites
              üè† *Comprovante de Resid√™ncia* - conta de luz/√°gua  
              üìã *Certid√£o de Nascimento/Casamento* - estado civil
              
              Me pe√ßa para enviar documentos que inicio a sequ√™ncia de envios com voc√™! üìÑ"
            - Se todos os documentos foram enviados, informe o pr√≥ximo passo
            - Mantenha o tom conversacional e amig√°vel
            - Use emojis para deixar mais amig√°vel
            - Use quebras de linha para separar as informa√ß√µes
            - Se n√£o h√° conversas anteriores, seja acolhedor e explique o processo

            Responda em JSON com:
            - "resumo": Resumo do contexto atual
            - "proxima_mensagem": Mensagem para enviar ao cliente
            - "contexto": Situa√ß√£o atual (ex: "aguardando_documentos", "documentos_completos", "iniciando_conversa")
            """
            
            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente especializado em an√°lise de conversas imobili√°rias. Responda sempre em JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            # Processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Resposta GPT-4 recebida: {resposta_texto[:100]}...")
            
            # Tentar fazer parse do JSON
            try:
                # ‚úÖ CORRE√á√ÉO: Limpeza robusta do JSON
                resposta_limpa = resposta_texto
                
                # Remover markdown se presente
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remover espa√ßos e quebras de linha extras
                resposta_limpa = resposta_limpa.strip()
                
                resultado = json.loads(resposta_limpa)
                logger.info(f"‚úÖ An√°lise GPT-4 conclu√≠da com sucesso")
                return resultado
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON: {e}")
                logger.warning(f"üîç Resposta original: {resposta_texto}")
                
                # ‚úÖ CORRE√á√ÉO: Fallback inteligente melhorado
                mensagem_limpa = resposta_texto
                
                # Se cont√©m estrutura JSON parcial, tentar extrair a mensagem
                if '"proxima_mensagem"' in resposta_texto:
                    try:
                        # Buscar o conte√∫do da proxima_mensagem
                        match = re.search(r'"proxima_mensagem":\s*"([^"]*)"', resposta_texto)
                        if match:
                            mensagem_limpa = match.group(1).replace('\\n', '\n')
                            logger.info(f"‚úÖ Mensagem extra√≠da do JSON parcial")
                        else:
                            # Fallback: usar texto ap√≥s dois pontos
                            if ':"' in resposta_texto:
                                mensagem_limpa = resposta_texto.split(':"')[1].split('"')[0]
                    except Exception as e_regex:
                        logger.warning(f"‚ö†Ô∏è Erro ao extrair mensagem: {e_regex}")
                        # Usar mensagem padr√£o se falhar
                        mensagem_limpa = "Analisei sua situa√ß√£o e vou continuar te ajudando com os pr√≥ximos passos!"
                else:
                    # Se n√£o tem estrutura JSON, usar o texto direto mas limitar tamanho
                    mensagem_limpa = resposta_texto[:200] if len(resposta_texto) > 200 else resposta_texto
                    # Remover caracteres JSON comuns que possam aparecer
                    mensagem_limpa = mensagem_limpa.replace('{"', '').replace('"}', '').replace('\\n', '\n')
                
                logger.info(f"üîÑ Fallback aplicado - Mensagem: {mensagem_limpa[:50]}...")
                
                return {
                    "resumo": "An√°lise conclu√≠da com fallback inteligente",
                    "proxima_mensagem": mensagem_limpa,
                    "contexto": "analise_texto_livre_com_fallback",
                    "erro": "json_parse_error_com_fallback"
                }
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise GPT-4: {str(e)}")
            return {
                "resumo": f"Erro na an√°lise: {str(e)}",
                "proxima_mensagem": "Vou analisar sua situa√ß√£o e retorno em breve. Obrigado pela paci√™ncia!",
                "contexto": "erro_analise"
            }

    def interpretar_intencao_mensagem(self, mensagem: str, remetente: str = None) -> Dict[str, Any]:
        """
        Interpretador inteligente para detectar inten√ß√µes em mensagens usando GPT
        
        Esta fun√ß√£o √© o INTERPRETADOR CENTRAL que processa TODAS as mensagens
        antes do fluxo principal, identificando:
        - Sauda√ß√µes (oi, ol√°, bom dia) ‚Üí Primeira mensagem da Bia
        - Solicita√ß√µes de menu (menu, op√ß√µes) ‚Üí Menu apropriado por tipo de usu√°rio
        - Conversas normais ‚Üí Continua fluxo original
        
        Args:
            mensagem (str): Texto da mensagem recebida do usu√°rio
            remetente (str, optional): N√∫mero do telefone (para contexto futuro)
            
        Returns:
            Dict com an√°lise da inten√ß√£o:
                - intencao: "saudacao" | "menu" | "conversa_normal" | "duvida_tecnica"
                - confianca: 0.0-1.0 (n√≠vel de certeza da IA)
                - bypass_fluxo: True se deve interceptar, False se continua normal
                - contexto: "primeira_interacao" | "usuario_conhecido"
                - acao_sugerida: "primeira_mensagem" | "enviar_menu" | "continuar_fluxo"
        
        Exemplo de uso:
            >>> interpretacao = service.interpretar_intencao_mensagem("oi, tudo bem?")
            >>> print(interpretacao["intencao"])  # "saudacao"
            >>> print(interpretacao["bypass_fluxo"])  # True
        """
        try:
            logger.info(f"üß† Interpretando inten√ß√£o da mensagem: {mensagem[:50]}...")
            
            # Prompt especializado para detectar inten√ß√µes
            prompt = f"""Analise esta mensagem do WhatsApp e identifique a inten√ß√£o do usu√°rio:

MENSAGEM: "{mensagem}"

Classifique a inten√ß√£o como:

1. "saudacao" - Se cont√©m cumprimentos como: oi, ol√°, bom dia, boa tarde, boa noite, hey, e a√≠, tudo bem, como vai, etc.

2. "menu" - Se solicita navega√ß√£o como: menu, op√ß√µes, voltar menu, menu inicial, mostrar op√ß√µes, escolhas, navegar, etc.

3. "conversa_normal" - Se cont√©m: CPF, n√∫meros, perguntas espec√≠ficas, documentos, informa√ß√µes pessoais

4. "duvida_tecnica" - Se cont√©m perguntas sobre: loca√ß√£o, processos, contratos, documenta√ß√£o, an√°lise, negocia√ß√£o

IMPORTANTE:
- Alta confian√ßa (>0.8) apenas se for CLARAMENTE uma sauda√ß√£o ou solicita√ß√£o de menu
- M√©dia confian√ßa (0.5-0.8) se houver d√∫vida
- Baixa confian√ßa (<0.5) se for amb√≠guo

Responda APENAS em JSON v√°lido:
{{
  "intencao": "saudacao|menu|conversa_normal|duvida_tecnica",
  "confianca": 0.0,
  "bypass_fluxo": true/false,
  "contexto": "primeira_interacao|usuario_conhecido",
  "acao_sugerida": "primeira_mensagem|enviar_menu|continuar_fluxo"
}}"""

            # Chamada para GPT com configura√ß√µes otimizadas
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """Voc√™ √© um analisador especializado em inten√ß√µes de mensagens para um sistema de atendimento imobili√°rio.

Sua fun√ß√£o √© identificar com precis√£o a inten√ß√£o real do usu√°rio:

- SAUDA√á√ïES: Cumprimentos gerais e iniciais de conversa
- MENU: Solicita√ß√µes expl√≠citas de navega√ß√£o ou op√ß√µes
- CONVERSA_NORMAL: Informa√ß√µes espec√≠ficas como CPF, dados pessoais
- DUVIDA_TECNICA: Perguntas sobre processos, contratos, loca√ß√£o

Seja conservador: apenas classifique como "saudacao" ou "menu" se tiver ALTA CERTEZA.
Caso contr√°rio, use "conversa_normal" para manter o fluxo original funcionando.

SEMPRE retorne JSON v√°lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consist√™ncia
                max_tokens=150    # Resposta curta e objetiva
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Resposta GPT: {resposta_texto[:100]}...")
            
            try:
                # ‚úÖ CORRE√á√ÉO: Limpeza robusta do JSON
                resposta_limpa = resposta_texto
                
                # Remover markdown se presente
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remover espa√ßos e quebras de linha extras
                resposta_limpa = resposta_limpa.strip()
                
                # Log da resposta limpa para debug
                logger.info(f"üßπ JSON limpo: {resposta_limpa[:150]}...")
                
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_limpa)
                
                # Validar campos obrigat√≥rios
                campos_obrigatorios = ["intencao", "confianca", "bypass_fluxo", "acao_sugerida"]
                for campo in campos_obrigatorios:
                    if campo not in resultado:
                        raise ValueError(f"Campo obrigat√≥rio ausente: {campo}")
                
                # Ajustar bypass_fluxo baseado na inten√ß√£o e confian√ßa
                if resultado["confianca"] < 0.7:
                    resultado["bypass_fluxo"] = False
                    resultado["acao_sugerida"] = "continuar_fluxo"
                else:
                    # Para sauda√ß√µes e menu com alta confian√ßa, sempre fazer bypass
                    if resultado["intencao"] in ["saudacao", "menu"]:
                        resultado["bypass_fluxo"] = True
                        if resultado["intencao"] == "saudacao":
                            resultado["acao_sugerida"] = "primeira_mensagem"
                        elif resultado["intencao"] == "menu":
                            resultado["acao_sugerida"] = "enviar_menu"
                
                logger.info(f"‚úÖ Inten√ß√£o detectada: {resultado['intencao']} (confian√ßa: {resultado['confianca']})")
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON do GPT: {e}")
                logger.warning(f"üîç Resposta original: {resposta_texto}")
                
                # ‚úÖ CORRE√á√ÉO: Fallback inteligente baseado no conte√∫do
                # Tentar extrair informa√ß√µes mesmo com JSON malformado
                intencao_detectada = "conversa_normal"
                confianca_detectada = 0.0
                
                # Buscar padr√µes na resposta mesmo sem JSON v√°lido
                if '"intencao": "saudacao"' in resposta_texto or '"saudacao"' in resposta_texto:
                    intencao_detectada = "saudacao"
                    confianca_detectada = 0.8
                elif '"intencao": "menu"' in resposta_texto or '"menu"' in resposta_texto:
                    intencao_detectada = "menu"
                    confianca_detectada = 0.8
                
                # Determinar a√ß√£o baseada na inten√ß√£o detectada
                if intencao_detectada == "saudacao":
                    acao_sugerida = "primeira_mensagem"
                    bypass_fluxo = True
                elif intencao_detectada == "menu":
                    acao_sugerida = "enviar_menu"
                    bypass_fluxo = True
                else:
                    acao_sugerida = "continuar_fluxo"
                    bypass_fluxo = False
                
                logger.info(f"üîÑ Fallback inteligente: {intencao_detectada} (confian√ßa: {confianca_detectada})")
                
                return {
                    "intencao": intencao_detectada,
                    "confianca": confianca_detectada,
                    "bypass_fluxo": bypass_fluxo,
                    "contexto": "usuario_conhecido", 
                    "acao_sugerida": acao_sugerida,
                    "erro": "json_parse_error_com_fallback"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico no interpretador de inten√ß√µes: {str(e)}")
            # Fallback seguro: sempre continuar fluxo normal em caso de erro
            return {
                "intencao": "conversa_normal",
                "confianca": 0.0,
                "bypass_fluxo": False,
                "contexto": "usuario_conhecido",
                "acao_sugerida": "continuar_fluxo",
                "erro": str(e)
            }


    def validar_dado_cliente(self, tipo_dado: str, valor: str) -> Dict[str, Any]:
        """
        Valida dados do cliente coletados durante processo de fechamento usando GPT
        
        Esta fun√ß√£o usa IA para validar se os dados fornecidos pelo colaborador
        s√£o v√°lidos para um processo de loca√ß√£o imobili√°ria.
        
        Args:
            tipo_dado (str): Tipo do dado a validar ("nome" | "telefone")
            valor (str): Valor fornecido pelo colaborador para valida√ß√£o
            
        Returns:
            Dict com resultado da valida√ß√£o:
                - valido: True se dado √© v√°lido, False se inv√°lido
                - valor_corrigido: Valor formatado/corrigido se necess√°rio
                - motivo_erro: Explica√ß√£o se inv√°lido
                - sugestao: Sugest√£o de corre√ß√£o se aplic√°vel
        
        Exemplos de uso:
            >>> resultado = service.validar_dado_cliente("nome", "Jo√£o Silva")
            >>> print(resultado["valido"])  # True
            
            >>> resultado = service.validar_dado_cliente("telefone", "11999999999")
            >>> print(resultado["valor_corrigido"])  # "(11) 99999-9999"
        """
        try:
            logger.info(f"üîç Validando {tipo_dado}: {valor[:30]}...")
            
            if tipo_dado == "nome":
                # Prompt para valida√ß√£o de nome
                prompt = f"""Analise se este √© um nome v√°lido para um cliente de loca√ß√£o imobili√°ria:

NOME: "{valor}"

Crit√©rios FLEX√çVEIS de valida√ß√£o:
1. Deve conter pelo menos 2 palavras (nome + sobrenome)
2. Deve usar caracteres alfab√©ticos (permitir acentos, espa√ßos)
3. N√£o deve conter n√∫meros ou s√≠mbolos especiais
4. Deve parecer um nome real de pessoa
5. Aceitar nomes compostos, duplos, estrangeiros

Exemplos V√ÅLIDOS: "Jo√£o Silva", "Maria Santos", "Jos√© da Silva", "Ana Beatriz", "Carlos Eduardo", "Andreia Robe", "Maria Jos√©", "Jo√£o Pedro"
Exemplos INV√ÅLIDOS: "Jo√£o", "123", "abc", "Jo√£o123", "@#$", "X Y", "A B"

IMPORTANTE: Seja FLEX√çVEL com nomes reais. Se parece um nome de pessoa v√°lido com pelo menos 2 palavras, ACEITE.

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Nome formatado corretamente",
  "motivo_erro": "Explica√ß√£o se inv√°lido",
  "sugestao": "Sugest√£o de corre√ß√£o se necess√°rio"
}}"""

            elif tipo_dado == "telefone":
                # Prompt para valida√ß√£o de telefone
                prompt = f"""Analise se este √© um telefone v√°lido brasileiro:

TELEFONE: "{valor}"

Crit√©rios de valida√ß√£o:
1. Deve ter 10 ou 11 d√≠gitos (com DDD)
2. DDD v√°lido brasileiro (11-99)
3. N√∫mero de celular ou fixo v√°lido
4. Pode ter ou n√£o formata√ß√£o
5. N√£o deve conter letras

Exemplos V√ÅLIDOS: "11999999999", "(11) 99999-9999", "1133334444"
Exemplos INV√ÅLIDOS: "999999999", "abc", "123", "00999999999"

Se v√°lido, formate como: (XX) XXXXX-XXXX para celular ou (XX) XXXX-XXXX para fixo

Responda APENAS em JSON:
{{
  "valido": true/false,
  "valor_corrigido": "Telefone formatado: (XX) XXXXX-XXXX",
  "motivo_erro": "Explica√ß√£o se inv√°lido",
  "sugestao": "Sugest√£o de corre√ß√£o se necess√°rio"
}}"""

            else:
                return {
                    "valido": False,
                    "motivo_erro": f"Tipo de dado n√£o suportado: {tipo_dado}",
                    "sugestao": "Use 'nome' ou 'telefone'"
                }

            # Chamada para GPT com configura√ß√µes de valida√ß√£o
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": """Voc√™ √© um validador especializado em dados de clientes para processos imobili√°rios.

Sua fun√ß√£o √© verificar se os dados fornecidos s√£o v√°lidos e √∫teis para um processo de loca√ß√£o.

Seja rigoroso na valida√ß√£o:
- Nomes devem ser completos e reais
- Telefones devem ser brasileiros v√°lidos
- Sempre formate corretamente os dados v√°lidos
- Forne√ßa explica√ß√µes claras para dados inv√°lidos

SEMPRE retorne JSON v√°lido sem texto adicional."""
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # Baixa criatividade para consist√™ncia na valida√ß√£o
                max_tokens=200
            )
            
            # Processar resposta do GPT
            resposta_texto = response.choices[0].message.content.strip()
            logger.info(f"ü§ñ Valida√ß√£o GPT: {resposta_texto[:100]}...")
            
            try:
                # ‚úÖ CORRE√á√ÉO: Limpeza robusta do JSON
                resposta_limpa = resposta_texto
                
                # Remover markdown se presente
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remover espa√ßos e quebras de linha extras
                resposta_limpa = resposta_limpa.strip()
                
                # Parse do JSON
                resultado = json.loads(resposta_limpa)
                
                # Validar campos obrigat√≥rios
                if "valido" not in resultado:
                    raise ValueError("Campo 'valido' ausente na resposta")
                
                # Adicionar informa√ß√µes de contexto
                resultado.update({
                    "tipo_dado": tipo_dado,
                    "valor_original": valor,
                    "timestamp_validacao": "now"
                })
                
                status = "‚úÖ V√ÅLIDO" if resultado["valido"] else "‚ùå INV√ÅLIDO"
                logger.info(f"{status} - {tipo_dado}: {valor[:20]}...")
                
                return resultado
                
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON de valida√ß√£o: {e}")
                logger.warning(f"üîç Resposta original: {resposta_texto}")
                
                # ‚úÖ CORRE√á√ÉO: Fallback inteligente
                # Tentar extrair informa√ß√µes b√°sicas mesmo com JSON malformado
                valido_detectado = False
                if '"valido": true' in resposta_texto or '"valido":true' in resposta_texto:
                    valido_detectado = True
                
                logger.info(f"üîÑ Fallback aplicado - V√°lido: {valido_detectado}")
                
                # Fallback: considerar inv√°lido se n√£o conseguir processar
                return {
                    "valido": valido_detectado,
                    "motivo_erro": "Erro interno na valida√ß√£o" if not valido_detectado else "Processamento com fallback",
                    "sugestao": f"Tente novamente com um {tipo_dado} mais claro",
                    "erro_processamento": str(e),
                    "tipo_dado": tipo_dado,
                    "valor_original": valor
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro cr√≠tico na valida√ß√£o de dados: {str(e)}")
            # Fallback seguro: sempre rejeitar em caso de erro
            return {
                "valido": False,
                "motivo_erro": "Erro t√©cnico na valida√ß√£o",
                "sugestao": f"Tente novamente fornecendo o {tipo_dado}",
                "erro_critico": str(e)
            }

    def responder_duvida_locacao(self, duvida: str, contexto_colaborador: dict = None) -> Dict[str, Any]:
        """
        IA especializada em responder d√∫vidas sobre negocia√ß√£o de loca√ß√£o para colaboradores
        
        Esta fun√ß√£o √© chamada quando um colaborador seleciona "Usar IA para D√∫vidas" no menu
        e envia uma pergunta relacionada a processos de loca√ß√£o, documentos, negocia√ß√£o, etc.
        
        Args:
            duvida (str): Pergunta/d√∫vida do colaborador sobre loca√ß√£o
            contexto_colaborador (dict, optional): Dados do colaborador (setor, nome, etc.)
            
        Returns:
            Dict: Resposta estruturada com:
                - resposta: Texto da resposta especializada
                - categoria: Categoria da d√∫vida (documentos, processo, juridico, etc.)
                - confianca: N√≠vel de confian√ßa da resposta (alto/medio/baixo)
                - sugestoes_extras: Sugest√µes adicionais se aplic√°vel
                
        Exemplo:
            >>> resultado = responder_duvida_locacao("Como validar comprovante de renda?")
            >>> print(resultado["resposta"])
            "Para validar comprovante de renda, voc√™ deve verificar..."
        """
        try:
            logger.info(f"ü§ñ Processando d√∫vida de loca√ß√£o: {duvida[:50]}...")
            
            # Extrair informa√ß√µes do colaborador se dispon√≠vel
            nome_colaborador = "Colaborador"
            setor_colaborador = "N√£o informado"
            
            if contexto_colaborador:
                nome_colaborador = contexto_colaborador.get('nome', 'Colaborador')
                setor_colaborador = contexto_colaborador.get('setor', 'N√£o informado')
            
            # Prompt especializado em negocia√ß√£o de loca√ß√£o
            prompt_sistema = f"""Voc√™ √© um ESPECIALISTA em NEGOCIA√á√ÉO DE LOCA√á√ÉO IMOBILI√ÅRIA e assistente para colaboradores da {self.company_name}.

            ESPECIALIDADES:
            üè† Processos de loca√ß√£o sem fiador
            üìÑ Documenta√ß√£o necess√°ria (RG, CPF, comprovantes)
            üí∞ An√°lise de renda e capacidade financeira
            üìã Contratos e termos legais
            üîç Valida√ß√£o de documentos
            üë• Relacionamento com clientes
            ‚öñÔ∏è Aspectos jur√≠dicos b√°sicos
            üìä Fluxos e procedimentos internos

            INSTRU√á√ïES:
            - Responda de forma PR√ÅTICA e OBJETIVA
            - Use linguagem PROFISSIONAL mas ACESS√çVEL
            - Forne√ßa PASSOS CONCRETOS quando aplic√°vel
            - Mencione DOCUMENTOS ESPEC√çFICOS quando necess√°rio
            - Use EMOJIS para organizar a informa√ß√£o
            - Se n√£o souber algo espec√≠fico da {self.company_name}, seja transparente
            - Foque em SOLU√á√ïES PR√ÅTICAS para o dia a dia

            FORMATO DA RESPOSTA:
            - Use quebras de linha para facilitar leitura no WhatsApp
            - Organize em t√≥picos quando necess√°rio
            - Seja direto e evite textos muito longos
            """

            prompt_usuario = f"""
            CONTEXTO DO COLABORADOR:
            üë§ Nome: {nome_colaborador}
            üè¢ Setor: {setor_colaborador}

            D√öVIDA:
            {duvida}

            Responda esta d√∫vida de forma especializada, considerando que √© um colaborador da {self.company_name} que precisa de orienta√ß√£o pr√°tica para seu trabalho di√°rio.

            Formate sua resposta em JSON com:
            - "resposta": Resposta detalhada e pr√°tica para a d√∫vida
            - "categoria": Categoria da d√∫vida (documentos|processo|juridico|relacionamento|financeiro|outros)
            - "confianca": N√≠vel de confian√ßa da resposta (alto|medio|baixo)
            - "sugestoes_extras": Array com sugest√µes adicionais ou pr√≥ximos passos (m√°ximo 3 sugest√µes)
            """

            # Fazer chamada para GPT-4
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": prompt_sistema},
                    {"role": "user", "content": prompt_usuario}
                ],
                temperature=0.3,  # Baixa temperatura para respostas mais consistentes
                max_tokens=800,   # Espa√ßo suficiente para resposta detalhada
                top_p=0.9
            )

            # Extrair e processar resposta
            resposta_texto = response.choices[0].message.content.strip()
            
            try:
                # ‚úÖ CORRE√á√ÉO: Limpeza robusta do JSON
                resposta_limpa = resposta_texto
                
                # Remover markdown se presente
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remover espa√ßos e quebras de linha extras
                resposta_limpa = resposta_limpa.strip()
                
                # Tentar fazer parse do JSON
                resultado = json.loads(resposta_limpa)
                
                # Validar estrutura da resposta
                if not all(key in resultado for key in ['resposta', 'categoria', 'confianca']):
                    raise ValueError("JSON n√£o cont√©m todas as chaves necess√°rias")
                
                # Garantir que sugestoes_extras seja uma lista
                if 'sugestoes_extras' not in resultado:
                    resultado['sugestoes_extras'] = []
                elif not isinstance(resultado['sugestoes_extras'], list):
                    resultado['sugestoes_extras'] = [str(resultado['sugestoes_extras'])]
                
                logger.info(f"‚úÖ D√∫vida processada - Categoria: {resultado['categoria']}")
                logger.info(f"üéØ Confian√ßa: {resultado['confianca']}")
                
                return {
                    "sucesso": True,
                    "resposta": resultado['resposta'],
                    "categoria": resultado['categoria'],
                    "confianca": resultado['confianca'],
                    "sugestoes_extras": resultado['sugestoes_extras'],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador
                }
                
            except (json.JSONDecodeError, ValueError) as e:
                # Se JSON inv√°lido, usar resposta como texto simples
                logger.warning(f"‚ö†Ô∏è Erro ao processar JSON: {str(e)}")
                logger.warning(f"üîç Resposta original: {resposta_texto}")
                
                # ‚úÖ CORRE√á√ÉO: Fallback inteligente melhorado
                resposta_limpa = resposta_texto
                
                # Remover markdown b√°sico
                resposta_limpa = resposta_limpa.replace('```json', '').replace('```', '').strip()
                
                # Tentar extrair pelo menos a resposta principal
                if '"resposta"' in resposta_limpa:
                    match = re.search(r'"resposta":\s*"([^"]*)"', resposta_limpa)
                    if match:
                        resposta_limpa = match.group(1).replace('\\n', '\n')
                
                # Detectar categoria se poss√≠vel
                categoria_detectada = "geral"
                if '"categoria"' in resposta_texto:
                    cat_match = re.search(r'"categoria":\s*"([^"]*)"', resposta_texto)
                    if cat_match:
                        categoria_detectada = cat_match.group(1)
                
                logger.info(f"üîÑ Fallback aplicado - Categoria: {categoria_detectada}")
                
                return {
                    "sucesso": True,
                    "resposta": resposta_limpa,
                    "categoria": categoria_detectada,
                    "confianca": "medio",
                    "sugestoes_extras": ["Posso esclarecer mais detalhes se precisar"],
                    "colaborador": nome_colaborador,
                    "setor": setor_colaborador,
                    "aviso": "Resposta processada com fallback inteligente",
                    "erro": "json_parse_error_com_fallback"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar d√∫vida de loca√ß√£o: {str(e)}")
            
            return {
                "sucesso": False,
                "resposta": "Desculpe, tive um problema t√©cnico ao processar sua d√∫vida. Pode reformular sua pergunta ou tentar novamente em alguns instantes?",
                "categoria": "erro",
                "confianca": "baixo",
                "sugestoes_extras": [
                    "Tente reformular a pergunta",
                    "Seja mais espec√≠fico sobre o tema",
                    "Verifique se √© uma d√∫vida sobre loca√ß√£o"
                ],
                "colaborador": nome_colaborador,
                "setor": setor_colaborador,
                "erro": str(e)
            } 

    def analisar_e_limpar_conversa_json(self, conversa_json: Dict[str, Any]) -> Dict[str, Any]:
        """
        üß† NOVA FUN√á√ÉO: Usa OpenAI para analisar e limpar JSON de conversa
        
        Funcionalidades:
        - Remove mensagens duplicadas
        - Remove logs t√©cnicos e do sistema
        - Formata mensagens de menu naturalmente
        - Remove detalhes t√©cnicos como "(row_id: iniciar_fechamento)"
        - Prepara JSON otimizado para banco de dados
        
        Args:
            conversa_json (Dict): JSON da conversa original
            
        Returns:
            Dict: JSON limpo e otimizado
        """
        try:
            logger.info("üß† Iniciando an√°lise e limpeza do JSON da conversa com OpenAI...")
            
            # Extrair mensagens para an√°lise
            mensagens_originais = conversa_json.get('messages', [])
            
            if not mensagens_originais:
                logger.warning("‚ö†Ô∏è Nenhuma mensagem encontrada para analisar")
                return conversa_json
            
            # Preparar dados para OpenAI
            mensagens_para_analise = []
            for i, msg in enumerate(mensagens_originais):
                mensagens_para_analise.append({
                    "index": i,
                    "id": msg.get('id'),
                    "timestamp": msg.get('timestamp'),
                    "sender": msg.get('sender'),
                    "content": msg.get('content', '')[:500],  # Limitar tamanho
                    "message_type": msg.get('message_type'),
                    "phase": msg.get('phase')
                })
            
            # Extrair dados dos participantes para detec√ß√£o inteligente
            participants = conversa_json.get('participants', {})
            client_data = participants.get('client', {})
            client_cpf = client_data.get('cpf', '')
            client_email = client_data.get('email', '')
            
            # ‚úÖ OTIMIZADO: Prompt mais assertivo e espec√≠fico
            prompt_analise = f"""
Voc√™ √© um ESPECIALISTA em limpeza de conversas WhatsApp. EXECUTE AS 4 REGRAS OBRIGAT√ìRIAS:

üéØ **REGRA 1 - CLASSIFICA√á√ÉO IA‚ÜíCORRETOR** (OBRIGAT√ìRIA):
- "‚úÖ *Dados do cliente coletados com sucesso!*" = sender="ia", receiver="corretor"
- "üöÄ Mensagem enviada ao cliente" = sender="ia", receiver="corretor"  
- "‚úÖ Iniciando contato com o cliente" = sender="ia", receiver="corretor"

üéØ **REGRA 2 - NATURALIZA√á√ÉO MENUS** (OBRIGAT√ìRIA):
- REMOVER: "(row_id: iniciar_fechamento)" ‚Üí "Iniciar Fechamento Loca√ß√£o"
- REMOVER: "(row_id: qualquer_codigo)" ‚Üí texto natural apenas

üéØ **REGRA 3 - DUPLICATAS** (OBRIGAT√ìRIA):
- Mensagens ID√äNTICAS = REMOVER a segunda ocorr√™ncia
- Conte√∫do 90%+ similar = REMOVER duplicata
- Seja AGRESSIVO na remo√ß√£o de duplicatas

üéØ **REGRA 4 - FLUXO PERDIDO** (OBRIGAT√ìRIA):
- IA pede CPF ‚Üí IA pede EMAIL = INSERIR resposta CPF do cliente
- IA pede EMAIL ‚Üí IA pede DATA = INSERIR resposta EMAIL do cliente

**REGRAS ESPEC√çFICAS OBRIGAT√ìRIAS:**

1. **CPF SEMPRE = CLIENTE**: Qualquer mensagem contendo CPF (11 d√≠gitos) deve ter sender="cliente"

2. **REMOVER MENSAGEM DUPLICADA DE CPF**: 
   - SEMPRE remover: "üìÑ Para prosseguir, preciso do seu CPF: (Somente n√∫meros, exemplo: 12345678901)"
   - MANTER apenas: "‚úÖ Perfeito! Para prosseguir, preciso do seu CPF."

3. **MENSAGENS IA‚ÜíCORRETOR (sender="ia", receiver="corretor")**:
   - "‚úÖ Iniciando contato com o cliente..."
   - "‚úÖ Dados do cliente coletados com sucesso!"
   - Qualquer mensagem come√ßando com "‚úÖ Dados do cliente"

4. **CLASSIFICA√á√ÉO CORRETA**:
   - Mensagem com CPF = sender="cliente"
   - Mensagem "‚úÖ Iniciando contato" = sender="ia", receiver="corretor"
   - Mensagem "‚úÖ Dados coletados" = sender="ia", receiver="corretor"

**MENSAGENS DA CONVERSA:**
{json.dumps(mensagens_para_analise, ensure_ascii=False, indent=2)}

**DADOS DO CLIENTE (para detec√ß√£o inteligente):**
- CPF: {client_cpf}
- Email: {client_email}

**DETEC√á√ÉO INTELIGENTE (REGRA CR√çTICA):**

EXEMPLO DE PROBLEMA:
1. msg_003: IA diz "preciso do seu CPF"
2. msg_004: IA detalha "Para prosseguir, preciso do seu CPF: (n√∫meros)"
3. msg_005: IA diz "Digite seu e-mail"  ‚Üê PROBLEMA! Cliente n√£o respondeu CPF!

REGRA: Se IA pede CPF e pr√≥xima mensagem √© IA pedindo EMAIL (sem resposta do cliente), ent√£o INSERIR:
{{
  "inserir_apos_index": [√≠ndice da mensagem que pede CPF],
  "sender": "cliente", 
  "content": "{client_cpf}",
  "motivo": "Resposta de CPF perdida detectada"
}}

OUTROS PADR√ïES:
- IA pede CPF ‚Üí IA pede EMAIL = FALTA resposta CPF
- IA pede EMAIL ‚Üí IA pede DATA = FALTA resposta EMAIL
- IA pede DATA ‚Üí IA pede CEP = FALTA resposta DATA

**RESPONDA EM JSON:**
{{
  "mensagens_para_manter": [√≠ndices das mensagens que devem ser mantidas],
  "mensagens_para_remover": [√≠ndices das mensagens que devem ser removidas],
  "mensagens_para_reformatar": [
    {{
      "index": √≠ndice,
      "novo_conteudo": "nova vers√£o sem detalhes t√©cnicos"
    }}
  ],
  "mensagens_para_reclassificar": [
    {{
      "index": √≠ndice,
      "novo_sender": "cliente|ia|corretor",
      "novo_receiver": "ia|corretor|cliente",
      "motivo": "classifica√ß√£o correta aplicada"
    }}
  ],
  "mensagens_para_inserir": [
    {{
      "inserir_apos_index": √≠ndice,
      "sender": "cliente",
      "content": "resposta do cliente",
      "motivo": "mensagem perdida detectada"
    }}
  ],
  "justificativa": "explica√ß√£o breve das mudan√ßas"
}}

**REGRAS:**
- Manter TODAS as mensagens essenciais do cliente e IA
- Remover apenas duplicatas √≥bvias e logs t√©cnicos
- Naturalizar menus: "Iniciar Fechamento Loca√ß√£o" (sem row_id)
- INSERIR mensagens perdidas do cliente automaticamente
- RECLASSIFICAR mensagens conforme regras espec√≠ficas
- Preservar fluxo da conversa
- Ser conservador - na d√∫vida, manter
"""

            # Chamar OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": """Voc√™ √© um especialista em an√°lise de conversas de WhatsApp. 

SUA MISS√ÉO ESPEC√çFICA: Detectar quando mensagens do cliente est√£o perdidas.

PADR√ÉO CR√çTICO A DETECTAR:
- IA pede CPF: "preciso do seu CPF"
- IA pede email: "Digite seu e-mail" (SEM o cliente ter respondido CPF)
- = PROBLEMA! Falta mensagem do cliente com CPF

QUANDO DETECTAR ESSE PADR√ÉO, voc√™ DEVE inserir a mensagem perdida usando os dados dos participants.

Seja PRECISO na detec√ß√£o de fluxos quebrados."""
                    },
                    {
                        "role": "user", 
                        "content": prompt_analise
                    }
                ],
                temperature=0.1,  # Baixa temperatura para consist√™ncia
                max_tokens=2000
            )
            
            # Processar resposta
            resposta_openai = response.choices[0].message.content.strip()
            
            # Limpar resposta removendo markdown
            resposta_limpa = resposta_openai.replace('```json', '').replace('```', '').strip()
            
            try:
                # ‚úÖ OTIMIZADO: Limpeza robusta do JSON (igual ao projeto anterior)
                if '```json' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```json')[1]
                if '```' in resposta_limpa:
                    resposta_limpa = resposta_limpa.split('```')[0]
                
                # Remove quebras de linha extras e normaliza
                resposta_limpa = " ".join(resposta_limpa.split())
                
                # Tentar parsear JSON da resposta
                analise = json.loads(resposta_limpa)
                logger.info(f"‚úÖ An√°lise OpenAI conclu√≠da: {analise.get('justificativa', 'N/A')}")
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Erro ao parsear JSON da OpenAI: {e}")
                logger.warning(f"üîç Resposta original: {resposta_openai[:200]}...")
                
                # ‚úÖ NOVO: Fallback inteligente que executa regras RAG b√°sicas
                logger.info("üîÑ Aplicando fallback inteligente com regras RAG...")
                analise = self._criar_analise_fallback_rag(mensagens_para_analise, resposta_openai)
            
            # Aplicar as mudan√ßas recomendadas
            mensagens_limpas = self._aplicar_limpeza_conversa(
                mensagens_originais, 
                analise,
                conversa_json
            )

            # ‚úÖ NOVO: Aplicar verifica√ß√£o final obrigat√≥ria
            mensagens_verificadas = self._verificacao_final_obrigatoria(mensagens_limpas)
            
            # ‚úÖ NOVO: Gerar relat√≥rio de auditoria
            relatorio_auditoria = self._auditar_resultado_limpeza(
                mensagens_originais, 
                mensagens_verificadas, 
                analise
            )

            # Criar JSON limpo
            conversa_limpa = conversa_json.copy()
            conversa_limpa['messages'] = mensagens_verificadas
            
            # Atualizar estat√≠sticas
            if 'conversation_summary' in conversa_limpa:
                conversa_limpa['conversation_summary']['total_messages'] = len(mensagens_verificadas)
                conversa_limpa['conversation_summary']['cleaned_by_ai'] = True
                conversa_limpa['conversation_summary']['original_count'] = len(mensagens_originais)
                conversa_limpa['conversation_summary']['removed_count'] = len(mensagens_originais) - len(mensagens_verificadas)
            
            # Adicionar metadata da limpeza
            conversa_limpa['ai_cleaning'] = {
                "cleaned_at": datetime.now().isoformat(),
                "original_message_count": len(mensagens_originais),
                "cleaned_message_count": len(mensagens_verificadas),
                "justificativa": analise.get('justificativa', 'Limpeza autom√°tica'),
                "removed_indices": analise.get('mensagens_para_remover', []),
                "reformatted_count": len(analise.get('mensagens_para_reformatar', [])),
                "inserted_count": len(analise.get('mensagens_para_inserir', [])),
                "inserted_messages": analise.get('mensagens_para_inserir', []),
                "auditoria": relatorio_auditoria  # ‚úÖ NOVO: Incluir relat√≥rio de auditoria
            }
            
            logger.info(f"üßπ Limpeza conclu√≠da: {len(mensagens_originais)} ‚Üí {len(mensagens_verificadas)} mensagens")
            
            return conversa_limpa
            
        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise/limpeza da conversa: {str(e)}")
            # Em caso de erro, retornar conversa original
            return conversa_json
    
    def _aplicar_limpeza_conversa(self, mensagens_originais: List[Dict], analise: Dict, conversa_json: Dict = None) -> List[Dict]:
        """
        Aplica as recomenda√ß√µes de limpeza da OpenAI
        
        Args:
            mensagens_originais: Lista de mensagens originais
            analise: Resultado da an√°lise OpenAI
            conversa_json: JSON completo da conversa (para dados dos participants)
            
        Returns:
            List: Mensagens limpas
        """
        try:
            mensagens_limpas = []
            indices_para_remover = set(analise.get('mensagens_para_remover', []))
            reformatacoes = {item['index']: item['novo_conteudo'] 
                           for item in analise.get('mensagens_para_reformatar', [])}
            
            # NOVO: Processar reclassifica√ß√µes
            reclassificacoes = {}
            for item in analise.get('mensagens_para_reclassificar', []):
                reclassificacoes[item['index']] = {
                    'sender': item.get('novo_sender'),
                    'receiver': item.get('novo_receiver'),
                    'motivo': item.get('motivo')
                }
            
            # Processar mensagens para inserir
            mensagens_para_inserir = {}
            for item in analise.get('mensagens_para_inserir', []):
                inserir_apos = item.get('inserir_apos_index', -1)
                mensagens_para_inserir[inserir_apos] = item
            
            for i, mensagem in enumerate(mensagens_originais):
                # Pular mensagens marcadas para remo√ß√£o
                if i in indices_para_remover:
                    logger.info(f"üóëÔ∏è Removendo mensagem {i}: {mensagem.get('content', '')[:50]}...")
                    continue
                
                # Criar c√≥pia da mensagem para modifica√ß√µes
                mensagem_processada = mensagem.copy()
                
                # Aplicar reformata√ß√£o se necess√°rio
                if i in reformatacoes:
                    mensagem_processada['content'] = reformatacoes[i]
                    mensagem_processada['ai_reformatted'] = True
                    logger.info(f"‚úèÔ∏è Reformatada mensagem {i}: {reformatacoes[i][:50]}...")
                
                # ‚úÖ OTIMIZADO: Aplicar reclassifica√ß√£o mais robusta
                if i in reclassificacoes:
                    reclass = reclassificacoes[i]
                    if reclass['sender']:
                        mensagem_processada['sender'] = reclass['sender']
                        mensagem_processada['sender_specific'] = reclass['sender']
                    if reclass['receiver']:
                        mensagem_processada['receiver'] = reclass['receiver']
                        mensagem_processada['receiver_specific'] = reclass['receiver']
                        
                        # ‚úÖ NOVO: Atualizar TODOS os campos relacionados
                        if 'metadata' not in mensagem_processada:
                            mensagem_processada['metadata'] = {}
                        mensagem_processada['metadata']['receiver_explicit'] = reclass['receiver']
                        mensagem_processada['interaction_type'] = f"{reclass['sender']}_{reclass['receiver']}"
                    
                    mensagem_processada['ai_reclassified'] = True
                    mensagem_processada['ai_reclassified_reason'] = reclass['motivo']
                    
                    logger.info(f"üîÑ Reclassificada mensagem {i}: {reclass['sender']}‚Üí{reclass['receiver']} - {reclass['motivo']}")
                
                # ‚úÖ NOVO: Detectar CPF e for√ßar classifica√ß√£o como cliente
                content = mensagem_processada.get('content', '')
                if re.search(r'\b\d{11}\b', content) and mensagem_processada.get('sender') != 'cliente':
                    mensagem_processada['sender'] = 'cliente'
                    mensagem_processada['sender_specific'] = 'cliente'
                    mensagem_processada['receiver'] = 'ia'
                    mensagem_processada['receiver_specific'] = 'ia'
                    mensagem_processada['ai_auto_classified'] = True
                    logger.info(f"üîÑ AUTO-CLASSIFICA√á√ÉO: Mensagem {i} com CPF ‚Üí cliente")
                
                mensagens_limpas.append(mensagem_processada)
                
                # Verificar se precisa inserir mensagem ap√≥s esta
                if i in mensagens_para_inserir:
                    nova_mensagem = mensagens_para_inserir[i]
                    
                    # Criar nova mensagem do cliente
                    mensagem_inserida = {
                        "id": f"msg_ai_inserted_{i+1}",
                        "timestamp": mensagem.get('timestamp', ''),
                        "sender": nova_mensagem.get('sender', 'cliente'),
                        "content": nova_mensagem.get('content', ''),
                        "message_type": "text",
                        "metadata": {
                            "receiver_explicit": "ia",
                            "enhanced_method": True,
                            "ai_inserted": True
                        },
                        "sender_specific": nova_mensagem.get('sender', 'cliente'),
                        "receiver_specific": "ia",
                        "interaction_type": "cliente_ia",
                        "phase": mensagem.get('phase', 'ia_cliente'),
                        "ai_inserted": True,
                        "ai_inserted_reason": nova_mensagem.get('motivo', 'Mensagem perdida detectada')
                    }
                    
                    mensagens_limpas.append(mensagem_inserida)
                    logger.info(f"üîÑ Inserida mensagem perdida ap√≥s {i}: {nova_mensagem.get('content', '')[:50]}...")
            
            return mensagens_limpas
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao aplicar limpeza: {e}")
            return mensagens_originais 
    
    def _criar_analise_fallback_rag(self, mensagens_para_analise: List[Dict], resposta_openai: str) -> Dict:
        """
        ‚úÖ NOVO: Fallback inteligente que executa regras RAG deterministicamente
        
        Quando JSON parse falha, aplica as 4 regras principais diretamente no c√≥digo:
        1. Classifica√ß√£o IA‚ÜíCorretor
        2. Naturaliza√ß√£o de Menus  
        3. Remo√ß√£o de Duplicatas
        4. Fluxo L√≥gico
        """
        logger.info("üéØ Executando regras RAG determin√≠sticas...")
        
        mensagens_para_remover = []
        mensagens_para_reformatar = []
        mensagens_para_reclassificar = []
        mensagens_para_inserir = []
        
        # ‚úÖ REGRA 1: CLASSIFICA√á√ÉO IA‚ÜíCORRETOR
        for i, msg in enumerate(mensagens_para_analise):
            content = msg.get('content', '').strip()
            sender = msg.get('sender', '')
            
            # Padr√µes espec√≠ficos para reclassifica√ß√£o
            padroes_ia_corretor = [
                "‚úÖ *Dados do cliente coletados com sucesso!*",
                "üöÄ Mensagem enviada ao cliente",
                "‚úÖ Dados do cliente coletados",
                "‚úÖ Iniciando contato com o cliente"
            ]
            
            for padrao in padroes_ia_corretor:
                if padrao in content and sender != 'corretor':
                    mensagens_para_reclassificar.append({
                        "index": i,
                        "novo_sender": "ia",
                        "novo_receiver": "corretor", 
                        "motivo": f"Padr√£o IA‚ÜíCorretor detectado: {padrao[:30]}..."
                    })
                    logger.info(f"üîÑ REGRA 1: Reclassificando mensagem {i} para IA‚ÜíCorretor")
                    break
        
        # ‚úÖ REGRA 2: NATURALIZA√á√ÉO DE MENUS
        for i, msg in enumerate(mensagens_para_analise):
            content = msg.get('content', '').strip()
            
            if "(row_id:" in content:
                # Remove row_id dos menus
                novo_conteudo = re.sub(r'\s*\(row_id:[^)]+\)', '', content)
                if novo_conteudo != content:
                    mensagens_para_reformatar.append({
                        "index": i,
                        "novo_conteudo": novo_conteudo.strip()
                    })
                    logger.info(f"üîÑ REGRA 2: Naturalizando menu {i}: {novo_conteudo[:50]}...")
        
        # ‚úÖ REGRA 3: REMO√á√ÉO DE DUPLICATAS (ultra agressiva)
        conteudos_vistos = {}
        for i, msg in enumerate(mensagens_para_analise):
            content = msg.get('content', '').strip()
            
            # Ignora mensagens muito curtas
            if len(content) < 3:
                continue
            
            # ‚úÖ NOVO: M√∫ltiplas estrat√©gias de normaliza√ß√£o
            estrategias = [
                # Estrat√©gia 1: Exata (case insensitive)
                content.lower().strip(),
                
                # Estrat√©gia 2: Sem pontua√ß√£o/emojis
                re.sub(r'[^\w\s]', '', content.lower()).strip(),
                
                # Estrat√©gia 3: S√≥ palavras principais (>3 chars)
                ' '.join([word for word in content.lower().split() if len(word) > 3]),
                
                # Estrat√©gia 4: N√∫meros apenas (para CPF/telefone)
                re.sub(r'[^\d]', '', content) if re.search(r'\d{6,}', content) else None
            ]
            
            for estrategia_idx, content_normalizado in enumerate(estrategias):
                if not content_normalizado:
                    continue
                
                # Chave √∫nica por estrat√©gia
                chave = f"{estrategia_idx}:{content_normalizado}"
                
                if chave in conteudos_vistos:
                    # Duplicata encontrada
                    primeiro_indice = conteudos_vistos[chave]
                    if i not in mensagens_para_remover:  # Evitar duplica√ß√£o na lista
                        mensagens_para_remover.append(i)
                        logger.info(f"üîÑ REGRA 3: Removendo duplicata {i} (estrat√©gia {estrategia_idx+1}, igual √† {primeiro_indice}): {content[:40]}...")
                    break
                else:
                    conteudos_vistos[chave] = i
        
        # ‚úÖ REGRA 4: FLUXO L√ìGICO - Detectar mensagens perdidas
        for i in range(len(mensagens_para_analise) - 1):
            msg_atual = mensagens_para_analise[i]
            msg_proxima = mensagens_para_analise[i + 1]
            
            content_atual = msg_atual.get('content', '').strip()
            content_proxima = msg_proxima.get('content', '').strip()
            sender_atual = msg_atual.get('sender', '')
            sender_proxima = msg_proxima.get('sender', '')
            
            # Detectar padr√£o: IA pede CPF ‚Üí IA pede EMAIL (falta resposta cliente)
            if (sender_atual == 'ia' and sender_proxima == 'ia' and
                'cpf' in content_atual.lower() and 'email' in content_proxima.lower()):
                
                # Inserir resposta de CPF perdida
                mensagens_para_inserir.append({
                    "inserir_apos_index": i,
                    "sender": "cliente",
                    "content": "12345678901",  # CPF padr√£o (ser√° ajustado com dados reais)
                    "motivo": "Resposta de CPF perdida detectada no fluxo"
                })
                logger.info(f"üîÑ REGRA 4: Inserindo CPF perdido ap√≥s mensagem {i}")
            
            # Detectar: IA pede EMAIL ‚Üí IA pede DATA (falta resposta email)
            elif (sender_atual == 'ia' and sender_proxima == 'ia' and
                  'email' in content_atual.lower() and 'data' in content_proxima.lower()):
                
                mensagens_para_inserir.append({
                    "inserir_apos_index": i,
                    "sender": "cliente", 
                    "content": "teste@exemplo.com",
                    "motivo": "Resposta de email perdida detectada no fluxo"
                })
                logger.info(f"üîÑ REGRA 4: Inserindo email perdido ap√≥s mensagem {i}")
        
        # Estat√≠sticas do fallback
        total_modificacoes = (len(mensagens_para_remover) + len(mensagens_para_reformatar) + 
                            len(mensagens_para_reclassificar) + len(mensagens_para_inserir))
        
        logger.info(f"üéØ FALLBACK RAG EXECUTADO:")
        logger.info(f"   - Reclassifica√ß√µes: {len(mensagens_para_reclassificar)}")
        logger.info(f"   - Naturaliza√ß√µes: {len(mensagens_para_reformatar)}")
        logger.info(f"   - Duplicatas removidas: {len(mensagens_para_remover)}")
        logger.info(f"   - Mensagens inseridas: {len(mensagens_para_inserir)}")
        logger.info(f"   - Total modifica√ß√µes: {total_modificacoes}")
        
        return {
            "mensagens_para_manter": list(range(len(mensagens_para_analise))),  # Manter todas exceto as removidas
            "mensagens_para_remover": mensagens_para_remover,
            "mensagens_para_reformatar": mensagens_para_reformatar,
            "mensagens_para_reclassificar": mensagens_para_reclassificar,
            "mensagens_para_inserir": mensagens_para_inserir,
            "justificativa": f"Fallback RAG determin√≠stico aplicado: {total_modificacoes} modifica√ß√µes executadas",
            "fallback_aplicado": True,
            "regras_executadas": ["classificacao_ia_corretor", "naturalizacao_menus", "remocao_duplicatas", "fluxo_logico"]
        }

    def _verificacao_final_obrigatoria(self, mensagens_limpas: List[Dict]) -> List[Dict]:
        """
        ‚úÖ NOVA FUN√á√ÉO: Verifica√ß√£o final determin√≠stica para garantir classifica√ß√µes corretas
        
        Esta fun√ß√£o executa uma verifica√ß√£o final OBRIGAT√ìRIA ap√≥s a limpeza OpenAI,
        aplicando regras determin√≠sticas para corrigir classifica√ß√µes incorretas.
        
        REGRAS CR√çTICAS:
        1. Mensagens com CPF (11 d√≠gitos) = sender="cliente"
        2. "‚úÖ *Dados do cliente coletados*" = sender="ia", receiver="corretor"
        3. "üöÄ Mensagem enviada ao cliente" = sender="ia", receiver="corretor"
        4. "‚úÖ Iniciando contato com o cliente" = sender="ia", receiver="corretor"
        
        Args:
            mensagens_limpas (List[Dict]): Mensagens ap√≥s limpeza OpenAI
            
        Returns:
            List[Dict]: Mensagens com classifica√ß√µes verificadas e corrigidas
        """
        try:
            logger.info("üîç Iniciando verifica√ß√£o final obrigat√≥ria...")
            
            mensagens_verificadas = []
            correcoes_aplicadas = 0
            
            for i, mensagem in enumerate(mensagens_limpas):
                mensagem_verificada = mensagem.copy()
                content = mensagem.get('content', '').strip()
                sender_atual = mensagem.get('sender', '')
                
                # ‚úÖ REGRA 1: CPF sempre = cliente
                if re.search(r'\b\d{11}\b', content):
                    if sender_atual != 'cliente':
                        mensagem_verificada['sender'] = 'cliente'
                        mensagem_verificada['sender_specific'] = 'cliente'
                        mensagem_verificada['receiver'] = 'ia'
                        mensagem_verificada['receiver_specific'] = 'ia'
                        mensagem_verificada['interaction_type'] = 'cliente_ia'
                        mensagem_verificada['verificacao_final_aplicada'] = True
                        mensagem_verificada['correcao_motivo'] = 'CPF detectado - for√ßado para cliente'
                        correcoes_aplicadas += 1
                        logger.info(f"üîß Corre√ß√£o CPF: Mensagem {i} reclassificada para cliente")
                
                # ‚úÖ REGRA 2: Padr√µes espec√≠ficos IA‚ÜíCorretor
                padroes_ia_corretor = [
                    "‚úÖ *Dados do cliente coletados",
                    "‚úÖ Dados do cliente coletados", 
                    "üöÄ Mensagem enviada ao cliente",
                    "‚úÖ Iniciando contato com o cliente"
                ]
                
                for padrao in padroes_ia_corretor:
                    if padrao in content:
                        if (sender_atual != 'ia' or 
                            mensagem.get('receiver') != 'corretor' or
                            mensagem.get('receiver_specific') != 'corretor'):
                            
                            mensagem_verificada['sender'] = 'ia'
                            mensagem_verificada['sender_specific'] = 'ia'
                            mensagem_verificada['receiver'] = 'corretor'
                            mensagem_verificada['receiver_specific'] = 'corretor'
                            mensagem_verificada['interaction_type'] = 'ia_corretor'
                            
                            # Atualizar metadata
                            if 'metadata' not in mensagem_verificada:
                                mensagem_verificada['metadata'] = {}
                            mensagem_verificada['metadata']['receiver_explicit'] = 'corretor'
                            
                            mensagem_verificada['verificacao_final_aplicada'] = True
                            mensagem_verificada['correcao_motivo'] = f'Padr√£o IA‚ÜíCorretor: {padrao[:30]}...'
                            correcoes_aplicadas += 1
                            logger.info(f"üîß Corre√ß√£o IA‚ÜíCorretor: Mensagem {i} - {padrao[:30]}...")
                        break
                
                # ‚úÖ REGRA 3: Garantir campos obrigat√≥rios
                if 'sender_specific' not in mensagem_verificada:
                    mensagem_verificada['sender_specific'] = mensagem_verificada.get('sender', 'ia')
                
                if 'receiver_specific' not in mensagem_verificada:
                    mensagem_verificada['receiver_specific'] = mensagem_verificada.get('receiver', 'ia')
                
                if 'interaction_type' not in mensagem_verificada:
                    sender = mensagem_verificada.get('sender', 'ia')
                    receiver = mensagem_verificada.get('receiver', 'ia')
                    mensagem_verificada['interaction_type'] = f"{sender}_{receiver}"
                
                mensagens_verificadas.append(mensagem_verificada)
            
            logger.info(f"‚úÖ Verifica√ß√£o final conclu√≠da: {correcoes_aplicadas} corre√ß√µes aplicadas")
            return mensagens_verificadas
            
        except Exception as e:
            logger.error(f"‚ùå Erro na verifica√ß√£o final: {str(e)}")
            # Em caso de erro, retornar mensagens originais
            return mensagens_limpas

    def _auditar_resultado_limpeza(self, mensagens_originais: List[Dict], mensagens_finais: List[Dict], analise_openai: Dict) -> Dict:
        """
        ‚úÖ NOVA FUN√á√ÉO: Auditoria completa do processo de limpeza
        
        Gera um relat√≥rio detalhado de todas as transforma√ß√µes aplicadas,
        estat√≠sticas de qualidade e m√©tricas de confiabilidade.
        
        Args:
            mensagens_originais (List[Dict]): Mensagens antes da limpeza
            mensagens_finais (List[Dict]): Mensagens ap√≥s toda a limpeza
            analise_openai (Dict): Resultado da an√°lise OpenAI
            
        Returns:
            Dict: Relat√≥rio completo de auditoria
        """
        try:
            logger.info("üìä Gerando relat√≥rio de auditoria...")
            
            # Estat√≠sticas b√°sicas
            total_original = len(mensagens_originais)
            total_final = len(mensagens_finais)
            total_removidas = total_original - total_final
            
            # An√°lise de classifica√ß√µes
            classificacoes_originais = {}
            classificacoes_finais = {}
            
            for msg in mensagens_originais:
                sender = msg.get('sender', 'indefinido')
                classificacoes_originais[sender] = classificacoes_originais.get(sender, 0) + 1
            
            for msg in mensagens_finais:
                sender = msg.get('sender', 'indefinido')
                classificacoes_finais[sender] = classificacoes_finais.get(sender, 0) + 1
            
            # Contar transforma√ß√µes espec√≠ficas
            mensagens_reformatadas = sum(1 for msg in mensagens_finais if msg.get('ai_reformatted'))
            mensagens_reclassificadas = sum(1 for msg in mensagens_finais if msg.get('ai_reclassified'))
            mensagens_inseridas = sum(1 for msg in mensagens_finais if msg.get('ai_inserted'))
            verificacoes_aplicadas = sum(1 for msg in mensagens_finais if msg.get('verificacao_final_aplicada'))
            
            # Detectar mensagens com CPF
            mensagens_com_cpf = 0
            cpf_classificado_cliente = 0
            
            for msg in mensagens_finais:
                content = msg.get('content', '')
                if re.search(r'\b\d{11}\b', content):
                    mensagens_com_cpf += 1
                    if msg.get('sender') == 'cliente':
                        cpf_classificado_cliente += 1
            
            # Calcular taxa de acerto CPF
            taxa_acerto_cpf = (cpf_classificado_cliente / mensagens_com_cpf * 100) if mensagens_com_cpf > 0 else 100
            
            # Detectar padr√µes IA‚ÜíCorretor
            padroes_ia_corretor = [
                "‚úÖ *Dados do cliente coletados",
                "‚úÖ Dados do cliente coletados",
                "üöÄ Mensagem enviada ao cliente", 
                "‚úÖ Iniciando contato com o cliente"
            ]
            
            mensagens_ia_corretor = 0
            ia_corretor_classificado_correto = 0
            
            for msg in mensagens_finais:
                content = msg.get('content', '')
                for padrao in padroes_ia_corretor:
                    if padrao in content:
                        mensagens_ia_corretor += 1
                        if (msg.get('sender') == 'ia' and 
                            msg.get('receiver') == 'corretor'):
                            ia_corretor_classificado_correto += 1
                        break
            
            # Taxa de acerto IA‚ÜíCorretor
            taxa_acerto_ia_corretor = (ia_corretor_classificado_correto / mensagens_ia_corretor * 100) if mensagens_ia_corretor > 0 else 100
            
            # Qualidade geral
            score_qualidade = (taxa_acerto_cpf + taxa_acerto_ia_corretor) / 2
            
            # Determinar status da limpeza
            if score_qualidade >= 95:
                status_limpeza = "EXCELENTE"
            elif score_qualidade >= 85:
                status_limpeza = "BOM"
            elif score_qualidade >= 70:
                status_limpeza = "REGULAR"
            else:
                status_limpeza = "REQUER_ATENCAO"
            
            # Construir relat√≥rio
            relatorio = {
                "timestamp": datetime.now().isoformat(),
                "estatisticas_gerais": {
                    "mensagens_originais": total_original,
                    "mensagens_finais": total_final,
                    "mensagens_removidas": total_removidas,
                    "taxa_reducao_pct": round((total_removidas / total_original * 100), 2) if total_original > 0 else 0
                },
                "transformacoes_aplicadas": {
                    "reformatadas": mensagens_reformatadas,
                    "reclassificadas": mensagens_reclassificadas,
                    "inseridas": mensagens_inseridas,
                    "verificacoes_finais": verificacoes_aplicadas,
                    "total_transformacoes": mensagens_reformatadas + mensagens_reclassificadas + mensagens_inseridas + verificacoes_aplicadas
                },
                "classificacoes": {
                    "originais": classificacoes_originais,
                    "finais": classificacoes_finais
                },
                "qualidade_classificacao": {
                    "mensagens_com_cpf": mensagens_com_cpf,
                    "cpf_classificado_cliente": cpf_classificado_cliente,
                    "taxa_acerto_cpf_pct": round(taxa_acerto_cpf, 2),
                    "mensagens_ia_corretor": mensagens_ia_corretor,
                    "ia_corretor_classificado_correto": ia_corretor_classificado_correto,
                    "taxa_acerto_ia_corretor_pct": round(taxa_acerto_ia_corretor, 2)
                },
                "score_qualidade": {
                    "score_geral": round(score_qualidade, 2),
                    "status": status_limpeza,
                    "confiabilidade": "ALTA" if score_qualidade >= 90 else "MEDIA" if score_qualidade >= 75 else "BAIXA"
                },
                "openai_analysis": {
                    "justificativa": analise_openai.get('justificativa', 'N/A'),
                    "fallback_aplicado": analise_openai.get('fallback_aplicado', False),
                    "regras_executadas": analise_openai.get('regras_executadas', [])
                }
            }
            
            logger.info(f"üìä Auditoria conclu√≠da - Score: {score_qualidade:.1f}% ({status_limpeza})")
            logger.info(f"üìà CPF: {taxa_acerto_cpf:.1f}% | IA‚ÜíCorretor: {taxa_acerto_ia_corretor:.1f}%")
            
            return relatorio
            
        except Exception as e:
            logger.error(f"‚ùå Erro na auditoria: {str(e)}")
            return {
                "timestamp": datetime.now().isoformat(),
                "erro": str(e),
                "status": "ERRO_AUDITORIA"
            }